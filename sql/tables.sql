-- CONNECT TO quantdb_test USER "quantdb-admin";

------------------- handling of datasources

CREATE table objects_internal(
-- TODO ...
id uuid DEFAULT gen_random_uuid() PRIMARY KEY,
label text,
curator_note text
);

CREATE TYPE remote_id_type AS ENUM (
-- FIXME XXX hardcoded remote conventions, essentially an optimization
'organization',
'dataset',
'collection',
'package',  -- XXX we do not currently support packages with multiple files so all packages entered should be to their file level
-- 'file',
-- technically also user is in here
'internal'  -- explicitly not remote (amusingly), TODO see if we want to do it this way ... this should have a foreign key constraint but given that objects are almost always external we pretend that our internal objects table is external, thus no foreign key, the alternative is to add id_interal and then a check constraint, there are other things we probably want in the objects table ... so better
);

CREATE table objects(
-- see sparcur.objects for context on naming, these are effectively datasources that are discrete files
-- yes, technically objects can also have quantiative values "measured" on them, but to avoid having to write CTEs or similar recursive queries, we keep them separate, right now we use the uuid directly as the primary key, at some point we may have to add an additional level of indirection to support multiple object id types, e.g. by identifying them by their checksums instead or something like that
id uuid PRIMARY KEY, -- XXX NOTE this reinforces the fact that we do not support packages with multiple files
id_type remote_id_type NOT NULL,
id_file integer, -- keep this for now to reduce the number of api calls, we may also need/want an s3 path or something
id_internal uuid references objects_internal(id),
constraint constraint_objects_remote_id_type_id_package check ((id_type != 'package') or (id_file is not null)),
constraint constraint_objects_remote_id_type_id_internal check ((id_type != 'internal') or (id_internal is not null and id = id_internal))
);

create table dataset_object(
-- not all objects are associated with a parent dataset
-- but for those that are we need to record the mapping
-- the real structure is hierarchical so a parent table
-- would make the most sense, but we don't need the
-- general case solution right now
dataset_id uuid references objects(id),
object_id uuid references objects(id),
PRIMARY KEY (dataset_id, object_id)
);

------------------- handling of units and aspects of values

create table units(
-- load from either UO or protcur sources
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
-- full unit expression can be composed from prefix + unit
-- or some other unit expression, we won't handle it in here
-- we just want to be able to recover the unit expression
-- use the URI structure or substructure that we already use
-- in sparc to store the unit here, but expect to unpack it
-- as needed
--composed_unit varchar, -- not clear we need this right now
-- unit_expression varchar,
label text,
iri text unique not null
-- if we want to be abel to search over units we will need to enhance this
);

create table aspects(
-- can prepopulate many of these as well
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
label text,
description text,
iri text unique not null
);

------------------- descriptors for instances, categorical, and quantiative values

create table class_measured(
-- FIXME aka inst_descriptors, instanceOf, is_a, subClassOf, etc.
-- the ontology class of the things being measured
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
label text,
description text,
iri text unique not null -- ontology_id,
--real_vs_symbolic, -- site vs roi, subject vs fiber/fascicle
--input_type,
);
--create table inst_descriptors( -- XXX redundant with class_measured, really just a naming issue
---- instance descriptors, used to define in advance where an instance identifier comes from and
---- give a type for how it is extracted, replaces instance_measured_type enum in a more operationally
---- sensible way that is consistent with the other mapping processes
--id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
--is_a integer references class_measured(id), -- yes this looks redundant, with quant_descriptors, but it is used to ensure that instance classes match when things can come from different processes, XXX BIG NOTE: if we are dealing with a heterogenous source, such as say, a hypothetical specimens.xlsx file then an auxillary path specifier may be needed to determine the actual value of class measured
--);

CREATE TYPE cat_range_type AS ENUM (
'open',
'controlled'
);

create table cat_descriptors(
-- otherwise known as predicates, for paralleism with quant
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
is_measuring integer references class_measured(id), -- domain specification, can be loose, but then we can't type check without the ontology
range cat_range_type, -- this is the best we can do for now
label text,
description text,
curator_note text, -- particularly re: mapping
UNIQUE (is_measuring, range, label)
);

CREATE TYPE quant_shape AS ENUM (
'scalar'
);

CREATE TYPE quant_agg_type AS ENUM (
'instance',
'function',
'summary',
'mean',
'media',
'mode',
'sum',
'min',
'max'
);

create table quant_descriptors(
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
shape quant_shape NOT NULL DEFAULT 'scalar', -- do we handle arrays and matricies here, like linkml ndarray issue, some double values e.g. for elipses TODO can we use shape to dispatch to appropriate tables or do we have a values table
unit integer references units(id),  -- mm FK to units
aspect integer references aspects(id),  -- distance, diameter, width
is_measuring integer references class_measured(id), -- class_measured -- points to class_measured measureable_thing -- subject, mouse, sample, cell, neuron, site, electrode, roi, fiber, fasicle -- should be at a higher level, a type of thing, not instances
label text unique not null, -- 99% of the time this is going to be used for retrieval so unn it
description text,
aggregation_type quant_agg_type NOT NULL DEFAULT 'instance', -- FIXME this impaces is_measuring as well
-- TODO if there is anything other than 'instance' in aggregation_type then we would expect
-- the measured_instance to point to a population of instance
curator_note text, -- particularly re: mapping
UNIQUE (unit, aspect, is_measuring, shape, aggregation_type)
);

------------------- instances (owl named individual)

create table sds_specimen( -- FIXME should probably expand to include site, pref, etc.
-- TODO this may need an equivalent id helper table e.g. for cw reva
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
dataset uuid references objects(id), -- FIXME we need a dataset independent version
specimen_id text, -- this is sample or subject sam-123 sub-123
-- parent_id integer references sds_specimen(id), -- do not do this in this way because it forces an order dependency when loading data
UNIQUE (dataset, specimen_id)
);

create table sds_specimen_equiv(
-- convenience cache of the full bidirectional
-- mapping of specimens that are equivalent to eachother
-- symmetric and transitive
left_thing integer references sds_specimen(id),
right_thing integer references sds_specimen(id),
PRIMARY KEY (left_thing, right_thing),
constraint sse_no_self check (left_thing != right_thing)
);

CREATE OR REPLACE FUNCTION get_all_equivs(new_left_thing integer, new_right_thing integer) RETURNS TABLE (
thing integer -- references sds_specimen(id)
) AS $$
BEGIN

RETURN QUERY
SELECT sse1.left_thing
FROM sds_specimen_equiv AS sse1
WHERE sse1.left_thing = new_left_thing
UNION
SELECT sse2.right_thing
FROM sds_specimen_equiv AS sse2
WHERE sse2.left_thing = new_left_thing
UNION
SELECT sse3.left_thing
FROM sds_specimen_equiv AS sse3
WHERE sse3.left_thing = new_right_thing
UNION
SELECT sse4.right_thing
FROM sds_specimen_equiv AS sse4
WHERE sse4.left_thing = new_right_thing
UNION
SELECT new_left_thing
UNION
SELECT new_right_thing;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION be_ins_sds_spec_expand_equiv() RETURNS trigger as $$ -- FIXME surely this goes on instance measured as well?
BEGIN

-- (a b) will also result in (b a) and that subsequently inserting
-- (c b) -> (b c) (c a) (a c) etc. yes the combinatorics get bad if you

/*
1. get the set of all left right including either of our news
2. take the cartesian product of the individuals to produce all possible pairs
3. add any pairs that are not in existing

you only need to do this for nl and nr appearing as the left thing because we populate the opposite

FIXME the way this is implemented using a before AND an after trigger is an absolute travesty
there is an infinitely better way to do this, but it is not coming to me right now
*/

WITH axis(thing) AS (SELECT * FROM get_all_equivs(NEW.left_thing, NEW.right_thing)),
all_pairs(left_thing, right_thing) AS (SELECT a1.thing, a2.thing FROM axis AS a1, axis AS a2 WHERE a1.thing != a2.thing),
known_pairs(left_thing, right_thing) AS
(
SELECT *
FROM sds_specimen_equiv AS sse
WHERE
sse.left_thing = NEW.left_thing
OR
sse.left_thing = NEW.right_thing
OR
sse.right_thing = NEW.left_thing
OR
sse.right_thing = NEW.right_thing
)
INSERT INTO sds_specimen_equiv (left_thing, right_thing)
SELECT * FROM all_pairs as ap WHERE (ap.left_thing, ap.right_thing) NOT IN (SELECT * FROM known_pairs)
;

RETURN NULL;

END;
$$ language plpgsql;

-- FIXME this is really on instance_measured though ??? or the superset of instance and sds entity?
CREATE OR REPLACE TRIGGER trigger_be_ins_sds_spec_expand_equiv BEFORE INSERT ON sds_specimen_equiv
FOR EACH ROW
WHEN (pg_trigger_depth() = 0)
EXECUTE PROCEDURE be_ins_sds_spec_expand_equiv();

--CREATE TYPE instance_measured_type AS ENUM (
--'sds', -- measurement or derived measure applying to a subject or sample
--'below-sds', -- something below the sds ontology level, e.g. fibers, fascicles
--'lifted-type' -- something below the sds ontology level but lifted, e.g. a gene id implying the rna transcribed for that gene that was extracted from/isolated form in a specific sample inevitably along with the rna for other genes as well
--);

create table instance_measured(
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
-- the exact instance measured, e.g. for fibers it will be the fiber id
-- in a single section, and then also possibly unified later using their
-- common fiber tracking naming algorithm
-- entity_type instance_measured_type, -- gene is a type level that implies "it is the expression of this gene in this context" where the context is implicit
--inst_desc integer references inst_descriptors(id),
inst_desc integer references class_measured(id),
dataset uuid references objects(id), -- FIXME we need a dataset independent version
formal_id text, -- could be same as specimen_id text or something from the sheet, if we are ingesting a whole file as a virtual section the id would be the file path, but idealy it would be the sample
local_identifier text, -- in spreadsheet mapping for the thing, could populate this automatically if we have a way to identify primary keys
--entity_id integer references entity(id),
-- entity_id text unique, -- sub- sam- -- could be iri from ttl file?
--file_row_thing integer,
-- could could have the gene id or similar, multiple levels of context

-- FIXME TODO replace with parent
specimen_id integer references sds_specimen(id) NOT NULL, -- always
subject_id integer references sds_specimen(id) NOT NULL, -- usually, edge cases are pools/pops XXX not null this for now and see what happens
sample_id integer references sds_specimen(id), -- sometimes
UNIQUE (dataset, formal_id)
);

--create table field_mapping(
-- not needed
-- mapping between the raw columns and the curated descriptors
-- what happens if a csv file changes?
-- TODO do we really want this fully normalized
--field,
--quant_desc,
--);

------------------- support for hierarchical relations
-- all the major types we deal with, instances, classes, and aspects have arbitrary transitive parent relations that are really what we want to query over to get things like subject_id, sample_id, etc. so just implement it

create table class_parent(
id integer references class_measured(id),
parent integer references class_measured(id),
PRIMARY KEY (id, parent)
);

-- single parent hierarchies for our major types
create table instance_parent( -- FIXME TODO really, merge instances with sds entities this with
id integer references instance_measured(id),
parent integer references instance_measured(id),
PRIMARY KEY (id, parent)
);

create table aspect_parent(
id integer references aspects(id),
parent integer references aspects(id),
PRIMARY KEY (id, parent)
);

------------------- object to instance mapping

CREATE TYPE field_value_type AS ENUM (
'single',
'multi' -- FIXME this is actually maybe-multi ...
);

CREATE TYPE field_address_type AS ENUM (
-- FIXME XXX hardcoded remote conventions, essentially an optimization
'tabular-header',
'tabular-alt-header',

'workbook-sheet-tabular-header',  -- DO NOT WANT
'workbook-sheet-tabular-alt-header',  -- DO NOT WANT

'json-path-with-types',  -- XXX only really works in python directly unless we use some convention like 0 or -1 to always imply int
'file-system-extracted',
'arbitrary-function'  -- point to some version controlled source and hope it is a function not a procedure ...
);

create table addresses(
-- this may be an over-normalization, but I think it makes sense, and it will
-- vastly simplify extractions from common metadata files while still supporting
-- the specification for bespoke extractions
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
address_type field_address_type,
value_type field_value_type DEFAULT 'single', -- FIXME not 100% on whether this is necessary, I think it is
field_address text,
curator_note text,
UNIQUE (address_type, field_address, value_type) -- XXX this is going to be a pain for anyone inserting, so be sure to use on conflict ignore and return the id
);

create table obj_inst_descriptors(
-- TODO the workflow for ingestion is to query these obj_x_descriptors tables and find cases where there are no assicated values of any kind and then run the ingest for those files
object_id uuid references objects(id), -- FIXME shouldn't this be unique? and the primary key? so we can do FK instead of the trigger below? maybe not? maybe there are objects that have, e.g. multiple data tables inside them or complex json that has multiple types? (sigh yeah that could get messy and might cause a proliferation of class_measured, or indicate insane data (lack of) organization)
--inst_desc integer references inst_descriptors(id),
inst_desc integer references class_measured(id),  -- FIXME naming
PRIMARY KEY (object_id, inst_desc),
-- TODO right now we aren't abstracting out address_type and address, but those are really what we need
field_address integer references addresses(id) NOT NULL,
class_address integer references addresses(id)
-- transformation from local_id (i.e. field contents) to formal_id is handled outside the db a record might be able to go in prov at some point?
-- this just tells you where to get it and the expected type and format, but doesn't say how those should be transformed
-- but most likely the mapping from local_id to formal_id should be fairly straight forward via the inst_desc table
);

CREATE OR REPLACE FUNCTION check_inst_desc_exists() RETURNS trigger as $$
BEGIN

IF EXISTS (SELECT FROM obj_inst_descriptors WHERE NEW.object_id = object_id) THEN
RETURN NEW;
ELSE
RAISE EXCEPTION 'object_id not in obj_inst_descriptors: %', NEW.object_id
USING HINT = 'object instance descriptor mappings should always be inserted first';
END IF;

END;
$$ language plpgsql;

------------------- object to quantitative mapping

create table obj_quant_descriptors(
-- this table is used to map both quantitative and categorical descriptors to package ids
-- this is what needs to be populated and maintained in order to run ingest, and we need
-- to be able to join package to dataset to reduce scope
-- NOTE object_id + quant_desc is sufficient, different fields must always have different descriptors if they contain different values
object_id uuid references objects(id),
quant_desc integer references quant_descriptors(id), -- quant desc has to be entered first
PRIMARY KEY (object_id, quant_desc),
field_address integer references addresses(id) NOT NULL,
-- XXX at the moment unit_address and aspect_address can only be used as a cross reference check
-- the pre-curation process must have already identified all possible quantiative descriptors
-- even if they are specified in the data, as such unit and aspect are not required
unit_address integer references addresses(id),
aspect_address integer references addresses(id),
class_address integer references addresses(id)
);

CREATE OR REPLACE TRIGGER trigger_be_ins_obj_quant_desc BEFORE INSERT ON obj_quant_descriptors FOR EACH ROW EXECUTE PROCEDURE check_inst_desc_exists();

------------------- object to categorical mapping

create table obj_cat_descriptors(
-- FIXME the split betweehn quant and cat is annoying, but I'm not sure we can do anything about it right now
-- essentially this is a result of not having a single descriptors table that has a type field and multiple columns
-- which is probably ok ...
object_id uuid references objects(id),
cat_desc integer references cat_descriptors(id),
PRIMARY KEY (object_id, cat_desc),
field_address integer references addresses(id) NOT NULL,
class_address integer references addresses(id)
);

CREATE OR REPLACE TRIGGER trigger_be_ins_obj_cat_desc BEFORE INSERT ON obj_cat_descriptors FOR EACH ROW EXECUTE PROCEDURE check_inst_desc_exists();

------------------- prov (old, replaced by object to x mapping)

/*
CREATE TYPE prov_type AS ENUM (
'external-field', -- e.g. from SPARC data file
'internal computation' -- e.g. a complex select statement
);

create table provenance(
-- 
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
type prov_type, -- this control the interpretation of the field source
field_name text, -- XXX no longer has meaning since we are using obj_quant_desc
field_source text, -- file path ??? pennsieve package id + dataset id  # XXX need to invert so that esra can get all measurements associated with a given file
-- field_source_source, -- TODO for the original image something was extracted from
-- XXX field source being file path implies sds entity id
obj_inst_desc integer references obj_inst_descriptors(id), -- this may seem like overkill, but it ensures that we have an explicit checkpoint where everything can be checked to ensure that classes, domain, range, etc. match before we pull out the value and stick it in the requisite table
obj_quant_desc integer references obj_quant_descriptors(id), -- quant desc has to be entered first
obj_cat_desc integer references obj_cat_descriptors(id),
constraint constraint_provenance_quant_or_cat check ((obj_quant_desc is not null or obj_cat_desc is not null) and not (obj_quant_desc is not null and obj_cat_desc is not null)) -- FIXME as written this only applies to the external-field case
);
-- if we want to use this to describe internal computations
-- field_name is the defined column name that the query returns
-- field_source is a query over quant_values or some join including it
-- quant_desc is the quant descriptor that is the output
*/

/*
create table interal_computation(
id,
query,
resulting_value,
resulting_units,
);
*/

-- two processes
-- 1 mapping of tabular schema "precuration" initially just in inserts.sql
-- 2 ingest
-- during mapping there are cases where we will need to map columns
-- to input instance metadata in addition to quant_values, specifically
-- for gene ids, this is context living inside vs outside the source file

-- how to deal with gene expression levels, don't really want a descriptor per gene

-- what are measured instances
-- mouse that has subject id
-- gene expression from a sample where there are 23k values
-- fiber diameter identified in one section vs across sections (becomes gene)

------------------- quantiative values

create table quant_values( -- atomic scalar values
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
--units varchar NOT NULL,
--aspect varchar NOT NULL, -- XXX vs metric
--input varchar NOT NULL,
--input_type , -- real or symbolic, site or roi etc.
--input_or_symbolic , --
-- FIXME categorical value ...
value numeric NOT NULL, -- FIXME might be an array or something? mostly present

object_id uuid references objects(id) NOT NULL,
inst_desc integer references class_measured(id) NOT NULL,
quant_desc integer references quant_descriptors(id) NOT NULL,  -- quant_desciptors id FIXME redundant with prov, but useful to simplify joins and for validation

FOREIGN KEY (object_id, inst_desc) REFERENCES obj_inst_descriptors (object_id, inst_desc),
FOREIGN KEY (object_id, quant_desc) REFERENCES obj_quant_descriptors (object_id, quant_desc),

measured_instance integer references instance_measured(id), -- instance_measured id -- links simliar measures on the same input (row)

orig_value varchar,
orig_units varchar,
-- FIXME TODO may also need original_type if such information was tracked
value_blob jsonb NOT NULL -- a full json represntation that may have weird shapes
-- UNIQUE (quant_desc, prov, measured_instance), -- FIXME issues with repeated measures? issues with values
);

-- TODO categorical values table over measured instances
-- can we also use categorical values to store relations to transitive samples, subjects, datasets, etc.

------------------- categorical values

create table controlled_terms(
-- this is kept separate from class_measured because class measured has stronger semantics
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
label text,
iri text unique not null
);

create table cat_values( -- categorical values
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
value_open text NOT NULL, -- always equivalent to orig_value
value_controlled integer references controlled_terms(id),

object_id uuid references objects(id) NOT NULL,
inst_desc integer references class_measured(id) NOT NULL,
cat_desc integer references cat_descriptors(id) NOT NULL,

FOREIGN KEY (object_id, inst_desc) REFERENCES obj_inst_descriptors (object_id, inst_desc),
FOREIGN KEY (object_id, cat_desc) REFERENCES obj_cat_descriptors (object_id, cat_desc),

measured_instance integer references instance_measured(id) -- instance_measured id -- links simliar measures on the same input (row)

);

------------------- convenience functions

CREATE OR REPLACE FUNCTION left_and_right_n(string text, n integer, OUT ret text) AS $$
BEGIN
SELECT LEFT(string, n) || ' ... ' || RIGHT(string, n) INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION unit_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM units WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION aspect_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM aspects WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION inst_desc_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM class_measured WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION cterm_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM controlled_terms WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION quant_desc_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM quant_descriptors WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION cat_desc_from_label_measuring_label(in_label text, in_is_measuring_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM cat_descriptors WHERE label = in_label AND is_measuring = inst_desc_from_label(in_is_measuring_label) INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION inst_from_dataset_id(in_dataset uuid, in_formal_id text, OUT ret integer) AS $$
BEGIN
SELECT id FROM instance_measured WHERE dataset = in_dataset AND formal_id = in_formal_id INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION spec_from_dataset_id(in_dataset uuid, in_specimen_id text, OUT ret integer) AS $$
BEGIN
SELECT id FROM sds_specimen WHERE dataset = in_dataset AND specimen_id = in_specimen_id INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION address_from_fadd_type_fadd(in_fadd_type field_address_type, in_fadd text, OUT ret integer) AS $$
BEGIN
SELECT id FROM addresses WHERE address_type = in_fadd_type AND field_address = in_fadd INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION address_from_fadd_type_fadd_vtype(in_fadd_type field_address_type, in_fadd text, in_vtype field_value_type, OUT ret integer) AS $$
BEGIN
/* -- bad footgun, don't do this
IF in_vtype IS NULL THEN
vtype := 'single';
ELSE
vtype := in_vtype;
END IF;
*/
SELECT id FROM addresses WHERE address_type = in_fadd_type AND field_address = in_fadd AND value_type = in_vtype INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_unextracte_objects() RETURNS TABLE(id_type remote_id_type, id uuid) AS $$
BEGIN

RETURN QUERY
-- more granular query to get object ids where cat or quant data have not
-- been extracted for the specific descriptors that have been specified
-- this makes it possible to do incremental extraction
SELECT objects.id_type, oqd.object_id FROM obj_quant_descriptors AS oqd
LEFT JOIN quant_values as qv
ON oqd.object_id = qv.object_id AND oqd.quant_desc = qv.quant_desc
JOIN objects ON oqd.object_id = objects.id
WHERE qv.object_id IS NULL OR qv.quant_desc IS NULL

UNION

SELECT objects.id_type, ocd.object_id FROM obj_cat_descriptors AS ocd
-- FIXME this can't detect cases where an UPDATE modified a cat_desc address value type or changed an address
-- e.g. if a curator makes a mistake, I guess we can have a force rerun option or add an AFTER UPDATE trigger
-- the obj_x_descriptor tables ??
LEFT JOIN cat_values as cv
ON ocd.object_id = cv.object_id AND ocd.cat_desc = cv.cat_desc
JOIN objects ON ocd.object_id = objects.id
WHERE cv.object_id IS NULL OR cv.cat_desc IS NULL;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_all_values_example() RETURNS TABLE(
value numeric,
value_open text,
value_controlled text,
unit_o_range text,
aspect_o_pred text,
inst_desc text, -- aka owl:Class
formal_id text,
specimen_id text,
subject_id text,
dset text,
obj text
) AS $$
BEGIN

RETURN QUERY

SELECT qv.value, NULL as open, NULL as controlled, u.label, a.label, id.label, im.formal_id, ss.specimen_id, sss.specimen_id, left_and_right_n(im.dataset::text, 4), left_and_right_n(qv.object_id::text, 4) FROM quant_values AS qv
JOIN quant_descriptors AS qd ON qv.quant_desc = qd.id
JOIN units AS u ON qd.unit = u.id
JOIN aspects AS a ON qd.aspect = a.id
JOIN class_measured AS id ON qv.inst_desc = id.id
JOIN instance_measured AS im ON qv.measured_instance = im.id
JOIN sds_specimen as ss ON im.specimen_id = ss.id
JOIN sds_specimen as sss ON im.subject_id = sss.id

UNION

SELECT NULL, cv.value_open, ct.label, cd.range::text, cd.label, id.label, im.formal_id, ss.specimen_id, sss.specimen_id, left_and_right_n(im.dataset::text, 4), left_and_right_n(cv.object_id::text, 4) FROM cat_values AS cv
JOIN cat_descriptors AS cd ON cv.cat_desc = cd.id
JOIN class_measured AS id ON cv.inst_desc = id.id
JOIN instance_measured AS im ON cv.measured_instance = im.id
JOIN controlled_terms AS ct ON cv.value_controlled = ct.id
JOIN sds_specimen as ss ON im.specimen_id = ss.id
JOIN sds_specimen as sss ON im.subject_id = sss.id

;

END;
$$ language plpgsql;

------------------- functions for hierarchies
-- we may ultimately use these in triggers or something to materialize e.g. subject_id into records
-- we might also use them as a cross reference check and still require subject_id to be present
-- for measured instances

-------- aspects

CREATE OR REPLACE FUNCTION get_aspect_parents(id_aspect_start integer) RETURNS TABLE (
parent integer
) AS $$
-- single transitive parent list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT ap0.parent FROM aspect_parent AS ap0 WHERE id = id_aspect_start
UNION ALL
SELECT ap.parent
FROM aspect_parent AS ap
JOIN tree AS t ON ap.id = t.id
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_aspect_parent_edges(id_aspect_start integer) RETURNS TABLE (
child integer,
parent integer
) AS $$
-- a slightly easier to read version that returns the edges
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parent) AS (
SELECT id, ap0.parent FROM aspect_parent AS ap0 WHERE id = id_aspect_start
UNION ALL
SELECT ap.id, ap.parent
FROM aspect_parent AS ap
JOIN tree AS t ON ap.id = t.parent
)
SELECT * FROM tree;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_all_aspect_parents() RETURNS TABLE (
id integer,
parents integer[]
) AS $$
-- a version that will generate the transitive parents for all records
-- for this it is better to populate top down
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parents) AS (
SELECT parent, ARRAY[]::integer[] FROM -- start from nodes with no parents
(SELECT ap0.parent FROM aspect_parent AS ap0 EXCEPT SELECT ap1.id FROM aspect_parent AS ap1)
UNION ALL
SELECT ap.id, ap.parent || t.parents
FROM aspect_parent AS ap
JOIN tree AS t ON ap.parent = t.child
)
SELECT * FROM tree;

END;
$$ language plpgsql;

-- TODO if we do not materialize the value we need into the child records
-- which is definitely the case for aspects and classes, then we also need
-- the inverse queries that return all children so that we can expand down
-- OR we populate giant cartesian tables to be used in joins

-------- classes

CREATE OR REPLACE FUNCTION get_class_parents(id_class_start integer) RETURNS TABLE (
parent integer
) AS $$
-- single transitive parent list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT cp0.parent FROM class_parent AS cp0 WHERE id = id_class_start
UNION ALL
SELECT cp.parent
FROM class_parent AS cp
JOIN tree AS t ON cp.id = t.id
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_class_parent_edges(id_class_start integer) RETURNS TABLE (
child integer,
parent integer
) AS $$
-- a slightly easier to read version that returns the edges
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parent) AS (
SELECT id, cp0.parent FROM class_parent AS cp0 WHERE id = id_class_start
UNION ALL
SELECT cp.id, cp.parent
FROM class_parent AS cp
JOIN tree AS t ON cp.id = t.parent
)
SELECT * FROM tree;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_all_class_parents() RETURNS TABLE (
id integer,
parents integer[]
) AS $$
-- a version that will generate the transitive parents for all records
-- for this it is better to populate top down
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parents) AS (
SELECT parent, ARRAY[]::integer[] FROM -- start from nodes with no parents
(SELECT cp0.parent FROM class_parent AS cp0 EXCEPT SELECT cp1.id FROM class_parent AS cp1)
UNION ALL
SELECT cp.id, cp.parent || t.parents
FROM class_parent AS cp
JOIN tree AS t ON cp.parent = t.child
)
SELECT * FROM tree;

END;
$$ language plpgsql;

-------- instances

CREATE OR REPLACE FUNCTION get_instance_parents(id_instance_start integer) RETURNS TABLE (
parent integer
) AS $$
-- single transitive parent list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT ip0.parent FROM instance_parent AS ip0 WHERE id = id_instance_start
UNION ALL
SELECT ip.parent
FROM instance_parent AS ip
JOIN tree AS t ON ip.id = t.id
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_instance_parent_edges(id_instance_start integer) RETURNS TABLE (
child integer,
parent integer
) AS $$
-- a slightly easier to read version that returns the edges
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parent) AS (
SELECT id, ip0.parent FROM instance_parent AS ip0 WHERE id = id_instance_start
UNION ALL
SELECT ip.id, ip.parent
FROM instance_parent AS ip
JOIN tree AS t ON ip.id = t.parent
)
SELECT * FROM tree;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_all_instance_parents() RETURNS TABLE (
id integer,
parents integer[]
) AS $$
-- a version that will generate the transitive parents for all records
-- for this it is better to populate top down
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parents) AS (
SELECT parent, ARRAY[]::integer[] FROM -- start from nodes with no parents
(SELECT ip0.parent FROM instance_parent AS ip0 EXCEPT SELECT ip1.id FROM instance_parent AS ip1)
UNION ALL
SELECT ip.id, ip.parent || t.parents
FROM instance_parent AS ip
JOIN tree AS t ON ip.parent = t.child
)
SELECT * FROM tree;

END;
$$ language plpgsql;

