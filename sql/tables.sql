-- CONNECT TO quantdb_test USER "quantdb-admin";

------------------- handling of datasources

CREATE TYPE oi_type AS ENUM (
'path-metadata',
'other'
);

CREATE table objects_internal(
-- TODO ...
id uuid DEFAULT gen_random_uuid() PRIMARY KEY,
type oi_type DEFAULT 'other',
dataset uuid,
updated_transitive timestamp,
label text,
curator_note text,
unique (dataset, updated_transitive),
constraint constraint_objects_internal_type_updated_transitive check (type != 'path-metadata' or (updated_transitive is not null and dataset is not null))
);

CREATE TYPE remote_id_type AS ENUM (
-- FIXME XXX hardcoded remote conventions, essentially an optimization
'organization',
'dataset',
'collection',
'package',  -- XXX we do not currently support packages with multiple files so all packages entered should be to their file level
-- 'file',
-- technically also user is in here
'quantdb'  -- aka internal explicitly not remote (amusingly), TODO see if we want to do it this way ... this should have a foreign key constraint but given that objects are almost always external we pretend that our internal objects table is external, thus no foreign key, the alternative is to add id_interal and then a check constraint, there are other things we probably want in the objects table ... so better
);

CREATE table objects(
-- see sparcur.objects for context on naming, these are effectively datasources that are discrete files
-- yes, technically objects can also have quantiative values "measured" on them, but to avoid having to write CTEs or similar recursive queries, we keep them separate, right now we use the uuid directly as the primary key, at some point we may have to add an additional level of indirection to support multiple object id types, e.g. by identifying them by their checksums instead or something like that
id uuid PRIMARY KEY, -- XXX NOTE this reinforces the fact that we do not support packages with multiple files
id_type remote_id_type NOT NULL,
id_file integer, -- keep this for now to reduce the number of api calls, we may also need/want an s3 path or something
id_internal uuid references objects_internal(id),
constraint constraint_objects_remote_id_type_id_package check ((id_type != 'package') or (id_file is not null)),
constraint constraint_objects_remote_id_type_id_internal check ((id_type != 'quantdb') or (id_internal is not null and id = id_internal))
);

CREATE INDEX IF NOT EXISTS idx_objects_id_internal ON objects (id_internal);

ALTER table objects_internal ADD constraint constraint_oi_dataset_fk FOREIGN KEY (dataset) references objects(id);

create table dataset_object(
-- not all objects are associated with a parent dataset
-- but for those that are we need to record the mapping
-- the real structure is hierarchical so a parent table
-- would make the most sense, but we don't need the
-- general case solution right now
dataset uuid references objects(id),
object uuid references objects(id),
PRIMARY KEY (dataset, object)
);

------------------- handling of units and aspects of values

create table units(
-- load from either UO or protcur sources
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
-- full unit expression can be composed from prefix + unit
-- or some other unit expression, we won't handle it in here
-- we just want to be able to recover the unit expression
-- use the URI structure or substructure that we already use
-- in sparc to store the unit here, but expect to unpack it
-- as needed
--composed_unit varchar, -- not clear we need this right now
-- unit_expression varchar,
label text unique not null,
iri text unique not null
-- if we want to be abel to search over units we will need to enhance this
);

create table aspects(
-- can prepopulate many of these as well
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
label text unique not null,
description text,
iri text unique not null
);

------------------- descriptors for instances, categorical, and quantiative values

create table descriptors_inst(
-- FIXME aka desc_instriptors, instanceOf, is_a, subClassOf, etc.
-- the ontology class of the things being measured
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
label text unique not null,
description text,
iri text unique not null -- ontology_id,
--real_vs_symbolic, -- site vs roi, subject vs fiber/fascicle
--input_type,
);
--create table desc_instriptors( -- XXX redundant with descriptors_inst, really just a naming issue
---- instance descriptors, used to define in advance where an instance identifier comes from and
---- give a type for how it is extracted, replaces values_inst_type enum in a more operationally
---- sensible way that is consistent with the other mapping processes
--id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
--is_a integer references descriptors_inst(id), -- yes this looks redundant, with descriptors_quant, but it is used to ensure that instance classes match when things can come from different processes, XXX BIG NOTE: if we are dealing with a heterogenous source, such as say, a hypothetical specimens.xlsx file then an auxillary path specifier may be needed to determine the actual value of class measured
--);

CREATE TYPE cat_range_type AS ENUM (
'open',
'controlled'
);

create table descriptors_cat(
-- otherwise known as predicates, for paralleism with quant
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
domain integer references descriptors_inst(id), -- domain specification, can be loose, but then we can't type check without the ontology
range cat_range_type, -- this is the best we can do for now
label text,
description text,
curator_note text, -- particularly re: mapping
UNIQUE (domain, range, label)
);

CREATE TYPE quant_shape AS ENUM (
'scalar'
);

CREATE TYPE quant_agg_type AS ENUM (
'instance',
'function',
'summary',
'mean',
'media',
'mode',
'sum',
'min',
'max'
);

create table descriptors_quant(
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
shape quant_shape NOT NULL DEFAULT 'scalar', -- do we handle arrays and matricies here, like linkml ndarray issue, some double values e.g. for elipses TODO can we use shape to dispatch to appropriate tables or do we have a values table
unit integer references units(id),  -- mm FK to units
aspect integer references aspects(id),  -- distance, diameter, width
domain integer references descriptors_inst(id), -- descriptors_inst -- points to descriptors_inst measureable_thing -- subject, mouse, sample, cell, neuron, site, electrode, roi, fiber, fasicle -- should be at a higher level, a type of thing, not instances
label text unique not null, -- 99% of the time this is going to be used for retrieval so unn it
description text,
aggregation_type quant_agg_type NOT NULL DEFAULT 'instance', -- FIXME this impaces domain as well
-- TODO if there is anything other than 'instance' in aggregation_type then we would expect
-- the instance to point to a population of instance
curator_note text, -- particularly re: mapping
UNIQUE (unit, aspect, domain, shape, aggregation_type)
);

------------------- instances (owl named individual)

/*
create table sds_specimen( -- FIXME should probably expand to include site, pref, etc.
-- TODO this may need an equivalent id helper table e.g. for cw reva
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
dataset uuid references objects(id), -- FIXME we need a dataset independent version
specimen_id text, -- this is sample or subject sam-123 sub-123
-- parent_id integer references sds_specimen(id), -- do not do this in this way because it forces an order dependency when loading data
UNIQUE (dataset, specimen_id)
);
*/

CREATE TYPE instance_type AS ENUM (
-- instance_type is needed in addition to instance_class because we only allow a single class for an instance
-- however we also need to be able to identify entities that map directly to sds entities (for now just subject
-- and sample) without having to parse ids or guess
'subject',
'sample',
'below' -- entities that might be part of a sample but were not derived from it during the experiment
--'performance',
--'lifted-type' -- something below the sds ontology level but lifted, e.g. a gene id implying the rna transcribed for that gene that was extracted from/isolated form in a specific sample inevitably along with the rna for other genes as well
);

create table values_inst(
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
-- the exact instance measured, e.g. for fibers it will be the fiber id
-- in a single section, and then also possibly unified later using their
-- common fiber tracking naming algorithm
-- entity_type values_inst_type, -- gene is a type level that implies "it is the expression of this gene in this context" where the context is implicit
--desc_inst integer references desc_instriptors(id),
type instance_type NOT NULL,
desc_inst integer references descriptors_inst(id),
dataset uuid references objects(id), -- FIXME we need a dataset independent version
id_formal text, -- could be same as specimen_id text or something from the sheet, if we are ingesting a whole file as a virtual section the id would be the file path, but idealy it would be the sample
local_identifier text, -- in spreadsheet mapping for the thing, could populate this automatically if we have a way to identify primary keys
--entity_id integer references entity(id),
-- entity_id text unique, -- sub- sam- -- could be iri from ttl file?
--file_row_thing integer,
-- could could have the gene id or similar, multiple levels of context

-- these can still be checked against the parent table and if we are using a trigger to check references, these can both be checked in one go
-- XXX we could, but choose not to enforce a foreign key on dataset and id_sub mapping to instance measured at this point
 -- FIXME cases where a cell line is the subject are going to confuse people, welcome to names not matching their meaning
id_sub text NOT NULL check (id_sub ~ '^sub-'), -- alternative to instance_subject FIXME should be require this even if type is subject for closure?
id_sam text check (id_sam ~ '^sam-'), -- alternative to instance_sample

-- FIXME TODO replace with parent
-- NOTE re: jgrethe comment: since we are moving to have a single values_inst table we want to avoid self reference foreign keys because it introduces an implicit order dependency, instead we will have a separate table beyond just the parent table so that we can insert without self reference, or something like that
--specimen_id integer references sds_specimen(id) NOT NULL, -- always
--id_sub integer references sds_specimen(id) NOT NULL, -- usually, edge cases are pools/pops XXX not null this for now and see what happens
--id_sam integer references sds_specimen(id), -- sometimes
UNIQUE (dataset, id_formal),
constraint constraint_values_inst_type_id_formal check (type = 'below' and not (id_formal ~ '^(sub|sam)-') or type = 'subject' and id_formal ~ '^sub-' or type = 'sample' and id_formal ~ '^sam-'),
constraint constraint_values_inst_type_id_sub check (type != 'subject' or (id_sub = id_formal and id_sam is null)),
constraint constraint_values_inst_type_id_sam check (type != 'sample' or (id_sam is not null and id_sam = id_formal)),
constraint constraint_values_inst_type_below check (type != 'below' or (id_sub is not null or id_sam is not null)) -- XXX there is not a general way to enforce that there must be a sample, e.g. a mri experiment can have virtual of sections of the brain without there being samples in the dataset at all, only subjects and performances
);

CREATE INDEX IF NOT EXISTS idx_values_inst_desc_inst ON values_inst (desc_inst);
CREATE INDEX IF NOT EXISTS idx_values_inst_dataset ON values_inst (dataset);
CREATE INDEX IF NOT EXISTS idx_values_inst_id_sub ON values_inst (id_sub);
CREATE INDEX IF NOT EXISTS idx_values_inst_id_sam ON values_inst (id_sam);
CREATE INDEX IF NOT EXISTS idx_values_inst_id_formal ON values_inst (id_formal);
CREATE INDEX IF NOT EXISTS idx_values_inst_dataset_id_sub ON values_inst (dataset, id_sub);
CREATE INDEX IF NOT EXISTS idx_values_inst_dataset_id_sam ON values_inst (dataset, id_sam);
CREATE INDEX IF NOT EXISTS idx_values_inst_dataset_id_formal ON values_inst (dataset, id_formal);


/*
create table instance_subject(
id integer references values_inst(id),
subject integer references values_inst(id),
PRIMARY KEY (id, subject)
);

CREATE OR REPLACE FUNCTION check_subject_is_subject() RETURNS trigger as $$
BEGIN
-- TODO may also want to check that the dataset ids match for sanity's sake
IF EXISTS (SELECT type FROM values_inst WHERE id = NEW.subject AND type = 'subject') THEN
RETURN NEW;
ELSE
RAISE EXCEPTION 'subject instance is not of type subject: %', (SELECT type FROM values_inst WHERE id = NEW.subject)
USING HINT = 'the values_inst referenced as a subject must have type subject';
END IF;
END;
$$ language plpgsql;

CREATE OR REPLACE TRIGGER trigger_be_ins_inst_sub BEFORE INSERT ON instance_subject FOR EACH ROW EXECUTE PROCEDURE check_subject_is_subject();

create table instance_sample(
id integer references values_inst(id),
sample integer references values_inst(id),
PRIMARY KEY (id, sample)
);

CREATE OR REPLACE FUNCTION check_sample_is_sample() RETURNS trigger as $$
BEGIN
-- TODO may also want to check that the dataset ids match for sanity's sake
IF EXISTS (SELECT type FROM values_inst WHERE id = NEW.sample AND type = 'sample') THEN
RETURN NEW;
ELSE
RAISE EXCEPTION 'sample instance is not of type sample: %', (SELECT type FROM values_inst WHERE id = NEW.sample)
USING HINT = 'the values_inst referenced as a sample must have type sample';
END IF;
END;
$$ language plpgsql;

CREATE OR REPLACE TRIGGER trigger_be_ins_inst_sam BEFORE INSERT ON instance_sample FOR EACH ROW EXECUTE PROCEDURE check_sample_is_sample();
*/

create table equiv_inst(
-- convenience cache of the full bidirectional
-- mapping of specimens that are equivalent to eachother
-- symmetric and transitive
left_thing integer references values_inst(id),
right_thing integer references values_inst(id),
PRIMARY KEY (left_thing, right_thing),
constraint sse_no_self check (left_thing != right_thing)
);

CREATE OR REPLACE FUNCTION get_all_equivs(new_left_thing integer, new_right_thing integer) RETURNS TABLE (
thing integer -- references sds_specimen(id)
) AS $$
BEGIN

RETURN QUERY
SELECT sse1.left_thing
FROM equiv_inst AS sse1
WHERE sse1.left_thing = new_left_thing
UNION
SELECT sse2.right_thing
FROM equiv_inst AS sse2
WHERE sse2.left_thing = new_left_thing
UNION
SELECT sse3.left_thing
FROM equiv_inst AS sse3
WHERE sse3.left_thing = new_right_thing
UNION
SELECT sse4.right_thing
FROM equiv_inst AS sse4
WHERE sse4.left_thing = new_right_thing
UNION
SELECT new_left_thing
UNION
SELECT new_right_thing;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION be_ins_sds_spec_expand_equiv() RETURNS trigger as $$ -- FIXME surely this goes on instance measured as well?
BEGIN

-- (a b) will also result in (b a) and that subsequently inserting
-- (c b) -> (b c) (c a) (a c) etc. yes the combinatorics get bad if you

/*
1. get the set of all left right including either of our news
2. take the cartesian product of the individuals to produce all possible pairs
3. add any pairs that are not in existing

you only need to do this for nl and nr appearing as the left thing because we populate the opposite

FIXME the way this is implemented using a before AND an after trigger is an absolute travesty
there is an infinitely better way to do this, but it is not coming to me right now
*/

WITH axis(thing) AS (SELECT * FROM get_all_equivs(NEW.left_thing, NEW.right_thing)),
all_pairs(left_thing, right_thing) AS (SELECT a1.thing, a2.thing FROM axis AS a1, axis AS a2 WHERE a1.thing != a2.thing),
known_pairs(left_thing, right_thing) AS
(
SELECT *
FROM equiv_inst AS sse
WHERE
sse.left_thing = NEW.left_thing
OR
sse.left_thing = NEW.right_thing
OR
sse.right_thing = NEW.left_thing
OR
sse.right_thing = NEW.right_thing
)
INSERT INTO equiv_inst (left_thing, right_thing)
SELECT * FROM all_pairs as ap WHERE (ap.left_thing, ap.right_thing) NOT IN (SELECT * FROM known_pairs)
;

RETURN NULL;

END;
$$ language plpgsql;

-- FIXME this is really on values_inst though ??? or the superset of instance and sds entity?
CREATE OR REPLACE TRIGGER trigger_be_ins_sds_spec_expand_equiv BEFORE INSERT ON equiv_inst
FOR EACH ROW
WHEN (pg_trigger_depth() = 0)
EXECUTE PROCEDURE be_ins_sds_spec_expand_equiv();

------------------- support for hierarchical relations
-- all the major types we deal with, instances, classes, and aspects have arbitrary transitive parent relations that are really what we want to query over to get things like id_sub, id_sam, etc. so just implement it

create table class_parent(
id integer references descriptors_inst(id),
parent integer references descriptors_inst(id),
PRIMARY KEY (id, parent)
);

-- single parent hierarchies for our major types
create table instance_parent( -- FIXME TODO really, merge instances with sds entities this with
id integer references values_inst(id),
parent integer references values_inst(id),
PRIMARY KEY (id, parent)
);

create table aspect_parent(
id integer references aspects(id),
parent integer references aspects(id),
PRIMARY KEY (id, parent)
);

------------------- object to instance mapping

CREATE TYPE field_value_type AS ENUM (
'single',
'multi' -- FIXME this is actually maybe-multi ...
);

CREATE TYPE address_type AS ENUM (
-- FIXME XXX hardcoded remote conventions, essentially an optimization
'constant',
--'curator', -- i.e. it came from the head of someone, will be very common for units and aspects FIXME TODO figure out how to document
-- "this came from tgbugs looking at a column header named thus_and_such_mm, maybe it is sufficient to just list the header itself but the type needs to be a bit different, tabular-header-value or json-path-with-types-property or something?
'tabular-header',
'tabular-alt-header',

'workbook-sheet-tabular-header',  -- DO NOT WANT
'workbook-sheet-tabular-alt-header',  -- DO NOT WANT

'json-path-with-types',  -- XXX only really works in python directly unless we use some convention like 0 or -1 to always imply int
'file-system-extracted',
'arbitrary-function'  -- point to some version controlled source and hope it is a function not a procedure ...
);

create table addresses(
-- this may be an over-normalization, but I think it makes sense, and it will
-- vastly simplify extractions from common metadata files while still supporting
-- the specification for bespoke extractions
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
addr_type address_type,
value_type field_value_type DEFAULT 'single', -- FIXME not 100% on whether this is necessary, I think it is
addr_field text,
curator_note text,
UNIQUE (addr_type, addr_field, value_type) -- XXX this is going to be a pain for anyone inserting, so be sure to use on conflict ignore and return the id
);

create table obj_desc_inst(
-- TODO the workflow for ingestion is to query these obj_x_descriptors tables and find cases where there are no assicated values of any kind and then run the ingest for those files
object uuid references objects(id), -- FIXME shouldn't this be unique? and the primary key? so we can do FK instead of the trigger below? maybe not? maybe there are objects that have, e.g. multiple data tables inside them or complex json that has multiple types? (sigh yeah that could get messy and might cause a proliferation of descriptors_inst, or indicate insane data (lack of) organization)
--desc_inst integer references desc_instriptors(id),
desc_inst integer references descriptors_inst(id),  -- FIXME naming
PRIMARY KEY (object, desc_inst),
-- TODO right now we aren't abstracting out addr_type and address, but those are really what we need
addr_field integer references addresses(id) NOT NULL,
addr_desc_inst integer references addresses(id),
-- transformation from local_id (i.e. field contents) to id_formal is handled outside the db a record might be able to go in prov at some point?
-- this just tells you where to get it and the expected type and format, but doesn't say how those should be transformed
-- but most likely the mapping from local_id to id_formal should be fairly straight forward via the desc_inst table
expect integer
);

CREATE OR REPLACE FUNCTION check_desc_inst_exists() RETURNS trigger as $$
BEGIN

IF EXISTS (SELECT FROM obj_desc_inst WHERE NEW.object = object) THEN
RETURN NEW;
ELSE
RAISE EXCEPTION 'object not in obj_desc_inst: %', NEW.object
USING HINT = 'object instance descriptor mappings should always be inserted first';
END IF;

END;
$$ language plpgsql;

------------------- object to quantitative mapping

create table obj_desc_quant(
-- this table is used to map both quantitative and categorical descriptors to package ids
-- this is what needs to be populated and maintained in order to run ingest, and we need
-- to be able to join package to dataset to reduce scope
-- NOTE object + desc_quant is sufficient, different fields must always have different descriptors if they contain different values
object uuid references objects(id),
desc_quant integer references descriptors_quant(id), -- quant desc has to be entered first
PRIMARY KEY (object, desc_quant),
addr_field integer references addresses(id) NOT NULL,
-- XXX at the moment addr_unit and addr_aspect can only be used as a cross reference check
-- the pre-curation process must have already identified all possible quantiative descriptors
-- even if they are specified in the data, as such unit and aspect are not required
addr_unit integer references addresses(id),
addr_aspect integer references addresses(id),
addr_desc_inst integer references addresses(id), -- FIXME does this actually go here? different name?
expect integer -- number of records matching this qd for this object that are expected, makes it possible to close the loop on ingest
);

CREATE OR REPLACE TRIGGER trigger_be_ins_obj_desc_quant BEFORE INSERT ON obj_desc_quant FOR EACH ROW EXECUTE PROCEDURE check_desc_inst_exists();

------------------- object to categorical mapping

create table obj_desc_cat(
-- FIXME the split betweehn quant and cat is annoying, but I'm not sure we can do anything about it right now
-- essentially this is a result of not having a single descriptors table that has a type field and multiple columns
-- which is probably ok ...
object uuid references objects(id),
desc_cat integer references descriptors_cat(id),
PRIMARY KEY (object, desc_cat),
addr_field integer references addresses(id) NOT NULL,
addr_desc_inst integer references addresses(id), -- FIXME does this actually go here? different name?
expect integer
);

CREATE OR REPLACE TRIGGER trigger_be_ins_obj_desc_cat BEFORE INSERT ON obj_desc_cat FOR EACH ROW EXECUTE PROCEDURE check_desc_inst_exists();

------------------- prov (old, replaced by object to x mapping)

/*
CREATE TYPE prov_type AS ENUM (
'external-field', -- e.g. from SPARC data file
'internal computation' -- e.g. a complex select statement
);

create table provenance(
--
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
type prov_type, -- this control the interpretation of the field source
field_name text, -- XXX no longer has meaning since we are using obj_desc_quant
field_source text, -- file path ??? pennsieve package id + dataset id  # XXX need to invert so that esra can get all measurements associated with a given file
-- field_source_source, -- TODO for the original image something was extracted from
-- XXX field source being file path implies sds entity id
obj_desc_inst integer references obj_desc_inst(id), -- this may seem like overkill, but it ensures that we have an explicit checkpoint where everything can be checked to ensure that classes, domain, range, etc. match before we pull out the value and stick it in the requisite table
obj_desc_quant integer references obj_desc_quant(id), -- quant desc has to be entered first
obj_desc_cat integer references obj_desc_cat(id),
constraint constraint_provenance_quant_or_cat check ((obj_desc_quant is not null or obj_desc_cat is not null) and not (obj_desc_quant is not null and obj_desc_cat is not null)) -- FIXME as written this only applies to the external-field case
);
-- if we want to use this to describe internal computations
-- field_name is the defined column name that the query returns
-- field_source is a query over values_quant or some join including it
-- desc_quant is the quant descriptor that is the output
*/

/*
create table interal_computation(
id,
query,
resulting_value,
resulting_units,
);
*/

-- two processes
-- 1 mapping of tabular schema "precuration" initially just in inserts.sql
-- 2 ingest
-- during mapping there are cases where we will need to map columns
-- to input instance metadata in addition to values_quant, specifically
-- for gene ids, this is context living inside vs outside the source file

-- how to deal with gene expression levels, don't really want a descriptor per gene

-- what are measured instances
-- mouse that has subject id
-- gene expression from a sample where there are 23k values
-- fiber diameter identified in one section vs across sections (becomes gene)

------------------- quantiative values

create table values_quant( -- atomic scalar values
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
--units varchar NOT NULL,
--aspect varchar NOT NULL, -- XXX vs metric
--input varchar NOT NULL,
--input_type , -- real or symbolic, site or roi etc.
--input_or_symbolic , --
-- FIXME categorical value ...
value numeric NOT NULL, -- FIXME might be an array or something? mostly present

object uuid references objects(id) NOT NULL,
desc_inst integer references descriptors_inst(id) NOT NULL,
desc_quant integer references descriptors_quant(id) NOT NULL,  -- desc_quantiptors id FIXME redundant with prov, but useful to simplify joins and for validation

FOREIGN KEY (object, desc_inst) REFERENCES obj_desc_inst (object, desc_inst),
FOREIGN KEY (object, desc_quant) REFERENCES obj_desc_quant (object, desc_quant),

instance integer references values_inst(id), -- values_inst id -- links simliar measures on the same input (row)

orig_value varchar,
orig_units varchar,
-- FIXME TODO may also need original_type if such information was tracked
value_blob jsonb NOT NULL -- a full json represntation that may have weird shapes
-- UNIQUE (desc_quant, prov, instance), -- FIXME issues with repeated measures? issues with values
);

CREATE INDEX IF NOT EXISTS idx_values_quant_object ON values_quant (object);
CREATE INDEX IF NOT EXISTS idx_values_quant_desc_inst ON values_quant (desc_inst);
CREATE INDEX IF NOT EXISTS idx_values_quant_desc_quant ON values_quant (desc_quant);
CREATE INDEX IF NOT EXISTS idx_values_quant_instance ON values_quant (instance);

-- TODO categorical values table over measured instances
-- can we also use categorical values to store relations to transitive samples, subjects, datasets, etc.

------------------- categorical values

create table controlled_terms(
-- this is kept separate from descriptors_inst because class measured has stronger semantics
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
label text unique not null,
iri text unique not null
);

create table values_cat( -- categorical values
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
value_open text, -- always equivalent to orig_value TODO may want this nullable due to the bottom case ... ?? yes, in bottom case we use a controlled term for integrity
value_controlled integer references controlled_terms(id),

object uuid references objects(id) NOT NULL,
desc_inst integer references descriptors_inst(id) NOT NULL,
desc_cat integer references descriptors_cat(id) NOT NULL,

FOREIGN KEY (object, desc_inst) REFERENCES obj_desc_inst (object, desc_inst),
FOREIGN KEY (object, desc_cat) REFERENCES obj_desc_cat (object, desc_cat),

instance integer references values_inst(id), -- values_inst id -- links simliar measures on the same input (row)

constraint constraint_values_cat_some_value check (value_open is not null or value_controlled is not null)

);

CREATE INDEX IF NOT EXISTS idx_values_cat_object ON values_cat (object);
CREATE INDEX IF NOT EXISTS idx_values_cat_desc_inst ON values_cat (desc_inst);
CREATE INDEX IF NOT EXISTS idx_values_cat_desc_cat ON values_cat (desc_cat);
CREATE INDEX IF NOT EXISTS idx_values_cat_instance ON values_cat (instance);
CREATE INDEX IF NOT EXISTS idx_values_cat_value_controlled ON values_cat (value_controlled);

------------------- convenience functions

CREATE FUNCTION ensure_test_user() RETURNS void AS $$
BEGIN
IF CURRENT_USER != 'quantdb-test-user' THEN
   RAISE EXCEPTION 'current_user % != quantdb-test-user', CURRENT_USER;
END IF;
END
$$ language plpgsql;

CREATE OR REPLACE FUNCTION left_and_right_n(string text, n integer, OUT ret text) AS $$
BEGIN
SELECT LEFT(string, n) || ' ... ' || RIGHT(string, n) INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION object_internal_from_dataset_updated_transitive(in_dataset uuid, in_updated_transitive timestamp, OUT ret uuid) AS $$
BEGIN
SELECT id FROM objects_internal WHERE dataset = in_dataset AND updated_transitive = in_updated_transitive INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION unit_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM units WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION aspect_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM aspects WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION desc_inst_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM descriptors_inst WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION cterm_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM controlled_terms WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION desc_quant_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM descriptors_quant WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION desc_cat_from_label_domain_label(in_label text, in_domain_label text, OUT ret integer) AS $$
BEGIN
IF in_domain_label IS NULL THEN
SELECT id FROM descriptors_cat WHERE label = in_label INTO ret;
ELSE
SELECT id FROM descriptors_cat WHERE label = in_label AND domain = desc_inst_from_label(in_domain_label) INTO ret;
END IF;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION inst_from_dataset_id(in_dataset uuid, in_id_formal text, OUT ret integer) AS $$
BEGIN
SELECT id FROM values_inst WHERE dataset = in_dataset AND id_formal = in_id_formal INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION insts_from_dataset_ids(in_dataset uuid, in_id_formals text[]) RETURNS TABLE(id integer, dataset uuid, id_formal text) AS $$
-- TODO this is the best we can do without having to deal with an array of pairs
-- since our unit of work is usually a single dataset this is probably ok
BEGIN
RETURN QUERY
SELECT im.id, im.dataset, im.id_formal FROM values_inst as im WHERE im.dataset = in_dataset AND im.id_formal = ANY (in_id_formals);
END;
$$ language plpgsql;

/*
CREATE OR REPLACE FUNCTION spec_from_dataset_id(in_dataset uuid, in_specimen_id text, OUT ret integer) AS $$
BEGIN
SELECT id FROM sds_specimen WHERE dataset = in_dataset AND specimen_id = in_specimen_id INTO ret;
END;
$$ language plpgsql;
*/

CREATE OR REPLACE FUNCTION address_from_fadd_type_fadd(in_fadd_type address_type, in_fadd text, OUT ret integer) AS $$
BEGIN
IF in_fadd IS NULL THEN
SELECT id FROM addresses WHERE addr_type = in_fadd_type AND addr_field IS NULL INTO ret;
ELSE
SELECT id FROM addresses WHERE addr_type = in_fadd_type AND addr_field = in_fadd INTO ret;
END IF;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION address_from_fadd_type_fadd_vtype(in_fadd_type address_type, in_fadd text, in_vtype field_value_type, OUT ret integer) AS $$
BEGIN
/* -- bad footgun, don't do this
IF in_vtype IS NULL THEN
vtype := 'single';
ELSE
vtype := in_vtype;
END IF;
*/
SELECT id FROM addresses WHERE addr_type = in_fadd_type AND addr_field = in_fadd AND value_type = in_vtype INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_unextracte_objects() RETURNS TABLE(id_type remote_id_type, id uuid) AS $$
BEGIN

RETURN QUERY
-- more granular query to get object ids where cat or quant data have not
-- been extracted for the specific descriptors that have been specified
-- this makes it possible to do incremental extraction
SELECT objects.id_type, oqd.object FROM obj_desc_quant AS oqd
LEFT JOIN values_quant as qv
ON oqd.object = qv.object AND oqd.desc_quant = qv.desc_quant
JOIN objects ON oqd.object = objects.id
WHERE qv.object IS NULL OR qv.desc_quant IS NULL

UNION

SELECT objects.id_type, ocd.object FROM obj_desc_cat AS ocd
-- FIXME this can't detect cases where an UPDATE modified a desc_cat address value type or changed an address
-- e.g. if a curator makes a mistake, I guess we can have a force rerun option or add an AFTER UPDATE trigger
-- the obj_x_descriptor tables ??
LEFT JOIN values_cat as cv
ON ocd.object = cv.object AND ocd.desc_cat = cv.desc_cat
JOIN objects ON ocd.object = objects.id
WHERE cv.object IS NULL OR cv.desc_cat IS NULL;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_all_values_example() RETURNS TABLE(
value numeric,
value_open text,
value_controlled text,
unit_o_range text,
aspect_o_pred text,
agg_type quant_agg_type,
desc_inst text, -- aka owl:Class
id_formal text,
id_sam text,
id_sub text,
dset text,
obj text
) AS $$
BEGIN

RETURN QUERY

SELECT qv.value, NULL as open, NULL as controlled, u.label, a.label, qd.aggregation_type, id.label, im.id_formal, saim.id_formal, suim.id_formal, left_and_right_n(im.dataset::text, 4), left_and_right_n(qv.object::text, 4)
FROM values_quant AS qv
JOIN descriptors_quant AS qd ON qv.desc_quant = qd.id
LEFT OUTER JOIN units AS u ON qd.unit = u.id -- loj because unitless is represented as null for now ?
JOIN aspects AS a ON qd.aspect = a.id
JOIN descriptors_inst AS id ON qv.desc_inst = id.id
JOIN values_inst AS im ON qv.instance = im.id

JOIN values_inst AS suim ON im.dataset = suim.dataset AND im.id_sub = suim.id_formal
LEFT OUTER JOIN values_inst AS saim ON im.dataset = saim.dataset AND im.id_sam = saim.id_formal -- loj since this id_sam is nullable

UNION

SELECT NULL, cv.value_open, ct.label, cd.range::text, cd.label, NULL, id.label, im.id_formal, saim.id_formal, suim.id_formal, left_and_right_n(im.dataset::text, 4), left_and_right_n(cv.object::text, 4)
FROM values_cat AS cv
JOIN controlled_terms AS ct ON cv.value_controlled = ct.id
JOIN descriptors_cat AS cd ON cv.desc_cat = cd.id
JOIN descriptors_inst AS id ON cv.desc_inst = id.id
JOIN values_inst AS im ON cv.instance = im.id

JOIN values_inst AS suim ON im.dataset = suim.dataset AND im.id_sub = suim.id_formal
LEFT OUTER JOIN values_inst AS saim ON im.dataset = saim.dataset AND im.id_sam = saim.id_formal -- loj since this id_sam is nullable

;

END;
$$ language plpgsql;

------------------- functions for hierarchies
-- we may ultimately use these in triggers or something to materialize e.g. id_sub into records
-- we might also use them as a cross reference check and still require id_sub to be present
-- for measured instances

-------- aspects

CREATE OR REPLACE FUNCTION get_child_aspect(id_aspect_start integer) RETURNS TABLE (
child integer
) AS $$
-- single transitive children list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT ap0.id FROM aspect_parent AS ap0 WHERE ap0.parent = id_aspect_start
UNION ALL
SELECT ap.id
FROM aspect_parent AS ap
JOIN tree AS t ON ap.parent = t.id
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_child_closed_aspect(id_aspect_start integer) RETURNS TABLE (
child integer
) AS $$
-- single transitive children list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT ap0.id FROM aspect_parent AS ap0 WHERE ap0.parent = id_aspect_start
UNION ALL
SELECT ap.id
FROM aspect_parent AS ap
JOIN tree AS t ON ap.parent = t.id
)
SELECT * FROM tree
UNION
SELECT id_aspect_start;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_aspect_child_edges(id_aspect_start integer) RETURNS TABLE (
parent integer,
child integer
) AS $$
-- lift transitive edges to direct
-- TODO for this to be differentially useful it would take multiple parents as an argument ... ???
BEGIN
RETURN QUERY
WITH RECURSIVE tree(parent, child) AS (
--SELECT ap0.parent, id FROM aspect_parent AS ap0 WHERE ap0.parent = id_aspect_start
SELECT id_aspect_start, id FROM aspect_parent AS ap0 WHERE ap0.parent = id_aspect_start
UNION ALL
--SELECT ap.parent, ap.id
SELECT id_aspect_start, ap.id
FROM aspect_parent AS ap
JOIN tree AS t ON ap.parent = t.child
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_parent_aspect(id_aspect_start integer) RETURNS TABLE (
parent integer
) AS $$
-- single transitive parent list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT ap0.parent FROM aspect_parent AS ap0 WHERE id = id_aspect_start
UNION ALL
SELECT ap.parent
FROM aspect_parent AS ap
JOIN tree AS t ON ap.id = t.id
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_parent_closed_aspect(id_aspect_start integer) RETURNS TABLE (
parent integer
) AS $$
-- single transitive parent list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT ap0.parent FROM aspect_parent AS ap0 WHERE id = id_aspect_start
UNION ALL
SELECT ap.parent
FROM aspect_parent AS ap
JOIN tree AS t ON ap.id = t.id
)
SELECT * FROM tree
UNION
SELECT id_aspect_start;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_aspect_parent_edges(id_aspect_start integer) RETURNS TABLE (
child integer,
parent integer
) AS $$
-- a slightly easier to read version that returns the edges
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parent) AS (
SELECT id, ap0.parent FROM aspect_parent AS ap0 WHERE id = id_aspect_start
UNION ALL
SELECT ap.id, ap.parent
FROM aspect_parent AS ap
JOIN tree AS t ON ap.id = t.parent
)
SELECT * FROM tree;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_all_parents_aspect() RETURNS TABLE (
id integer,
parents integer[]
) AS $$
-- a version that will generate the transitive parents for all records
-- for this it is better to populate top down
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parents) AS (
SELECT parent, ARRAY[]::integer[] FROM -- start from nodes with no parents
(SELECT ap0.parent FROM aspect_parent AS ap0 EXCEPT SELECT ap1.id FROM aspect_parent AS ap1)
UNION ALL
SELECT ap.id, ap.parent || t.parents
FROM aspect_parent AS ap
JOIN tree AS t ON ap.parent = t.child
)
SELECT * FROM tree;

END;
$$ language plpgsql;

-- TODO if we do not materialize the value we need into the child records
-- which is definitely the case for aspects and classes, then we also need
-- the inverse queries that return all children so that we can expand down
-- OR we populate giant cartesian tables to be used in joins

-------- classes

CREATE OR REPLACE FUNCTION get_child_desc_inst(id_class_start integer) RETURNS TABLE (
child integer
) AS $$
-- single transitive children list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT cp0.id FROM class_parent AS cp0 WHERE cp0.parent = id_class_start
UNION ALL
SELECT cp.id
FROM class_parent AS cp
JOIN tree AS t ON cp.parent = t.id
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_child_closed_desc_inst(id_class_start integer) RETURNS TABLE (
child integer
) AS $$
-- single transitive children list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT cp0.id FROM class_parent AS cp0 WHERE cp0.parent = id_class_start
UNION ALL
SELECT cp.id
FROM class_parent AS cp
JOIN tree AS t ON cp.parent = t.id
)
SELECT * FROM tree
UNION
SELECT id_class_start;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_parent_desc_inst(id_class_start integer) RETURNS TABLE (
parent integer
) AS $$
-- single transitive parent list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT cp0.parent FROM class_parent AS cp0 WHERE id = id_class_start
UNION ALL
SELECT cp.parent
FROM class_parent AS cp
JOIN tree AS t ON cp.id = t.id
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_parent_closed_desc_inst(id_class_start integer) RETURNS TABLE (
parent integer
) AS $$
-- single transitive parent list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT cp0.parent FROM class_parent AS cp0 WHERE id = id_class_start
UNION ALL
SELECT cp.parent
FROM class_parent AS cp
JOIN tree AS t ON cp.id = t.id
)
SELECT * FROM tree
UNION
SELECT id_class_start;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_class_parent_edges(id_class_start integer) RETURNS TABLE (
child integer,
parent integer
) AS $$
-- a slightly easier to read version that returns the edges
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parent) AS (
SELECT id, cp0.parent FROM class_parent AS cp0 WHERE id = id_class_start
UNION ALL
SELECT cp.id, cp.parent
FROM class_parent AS cp
JOIN tree AS t ON cp.id = t.parent
)
SELECT * FROM tree;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_all_parents_desc_inst() RETURNS TABLE (
id integer,
parents integer[]
) AS $$
-- a version that will generate the transitive parents for all records
-- for this it is better to populate top down
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parents) AS (
SELECT parent, ARRAY[]::integer[] FROM -- start from nodes with no parents
(SELECT cp0.parent FROM class_parent AS cp0 EXCEPT SELECT cp1.id FROM class_parent AS cp1)
UNION ALL
SELECT cp.id, cp.parent || t.parents
FROM class_parent AS cp
JOIN tree AS t ON cp.parent = t.child
)
SELECT * FROM tree;

END;
$$ language plpgsql;

-------- instances

CREATE OR REPLACE FUNCTION get_parent_inst(id_instance_start integer) RETURNS TABLE (
parent integer
) AS $$
-- single transitive parent list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT ip0.parent FROM instance_parent AS ip0 WHERE id = id_instance_start
UNION ALL
SELECT ip.parent
FROM instance_parent AS ip
JOIN tree AS t ON ip.id = t.id
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_instance_parent_edges(id_instance_start integer) RETURNS TABLE (
child integer,
parent integer
) AS $$
-- a slightly easier to read version that returns the edges
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parent) AS (
SELECT id, ip0.parent FROM instance_parent AS ip0 WHERE id = id_instance_start
UNION ALL
SELECT ip.id, ip.parent
FROM instance_parent AS ip
JOIN tree AS t ON ip.id = t.parent
)
SELECT * FROM tree;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_all_parents_inst() RETURNS TABLE (
id integer,
parents integer[]
) AS $$
-- a version that will generate the transitive parents for all records
-- for this it is better to populate top down
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parents) AS (
SELECT parent, ARRAY[]::integer[] FROM -- start from nodes with no parents
(SELECT ip0.parent FROM instance_parent AS ip0 EXCEPT SELECT ip1.id FROM instance_parent AS ip1)
UNION ALL
SELECT ip.id, ip.parent || t.parents
FROM instance_parent AS ip
JOIN tree AS t ON ip.parent = t.child
)
SELECT * FROM tree;

END;
$$ language plpgsql;


CREATE OR REPLACE FUNCTION check_inst_susa_parent() RETURNS trigger as $$
-- FIXME as implemented the user has to know when to call this function OR we have to make it
-- run as a trigger after any insert into and require that insert into values must include the
-- full parent hierarchy for any and all instances that have been added to the instance_parent
-- table ... actually ... this could run as a trigger if we require that inserts into the
-- instance_parent table always be done in order so that the parents are always in the table
-- before the children, it does mean that we can disable the trigger when loading from a dump
-- though ...
DECLARE
rec record;
BEGIN

WITH
parents AS (SELECT im FROM values_inst AS im WHERE im.id IN (SELECT * FROM get_parent_inst(NEW.id))),
subjects AS (SELECT suim FROM values_inst AS im
JOIN values_inst AS suim ON im.dataset = suim.dataset AND suim.id_formal = im.id_sub AND suim.id != NEW.id
WHERE im.id = NEW.id),
samples AS (SELECT saim FROM values_inst AS im
JOIN values_inst AS saim ON im.dataset = saim.dataset AND saim.id_formal = im.id_sam AND saim.id != NEW.id
WHERE im.id = NEW.id)
SELECT -- FIXME surely there is a more efficient way to do this
(((SELECT count(*) FROM samples) > 0 OR  (SELECT count(*) from subjects) > 0) AND (SELECT count(*) FROM parents) = 0) AS one,
( (SELECT count(*) FROM samples) = 0 AND (SELECT count(*) from subjects) = 0  AND (SELECT count(*) FROM parents) > 0) AS two,
(    (SELECT count(*) FROM (SELECT * FROM parents INTERSECT SELECT * FROM subjects)) = (SELECT count(*) FROM subjects)
AND  (SELECT count(*) FROM (SELECT * FROM parents INTERSECT SELECT * FROM samples))  = (SELECT count(*) FROM samples)) AS three
/*
-- we cannot check against parents in this last case because it can contain intermediates therefore we can only check parents contain all referenced subjects and samples, going the other way around we know we will be missing any intervening samples, but those will have been checked when they were inserted
AND  (SELECT count(*) FROM (SELECT * FROM parents INTERSECT SELECT * FROM (SELECT * FROM subjects UNION SELECT * FROM samples))) = (SELECT count(*) FROM parents))
*/
INTO rec;

/*
FIXME TODO must handle the multi-parent case, which can happen when samples are
derived from multiple subjects, in those cases if we want this to work as it does
now then we have to reify subject populations and sample populations for the purposes
of referential integrity
*/

IF rec.one THEN

RAISE EXCEPTION 'parents missing for instance which references a subject or a sample: %', (select id_formal from values_inst where id = NEW.id) --, .id_sub, .id_sam
USING HINT = 'forgot to insert into the parents table';

ELSIF rec.two THEN

RAISE EXCEPTION 'subjects and samples missing on instance when there are parents: % %', (select id_formal from values_inst where id = NEW.id), (SELECT vi.id_formal FROM values_inst as vi JOIN get_parent_inst(NEW.id) as gpi ON vi.id = gpi.parent)
USING HINT = 'instance did not include subject/sample reference when there should have been one';

ELSIF NOT rec.three THEN

RAISE EXCEPTION 'mismatch between parents, subjects, or samples: % %', (select id_formal from values_inst where id = NEW.id), (SELECT vi.id_formal FROM values_inst as vi JOIN get_parent_inst(NEW.id) as gpi ON vi.id = gpi.parent)--, NEW.id_sub, NEW.id_sam
USING HINT = 'there might be extra parents, subjects, or samples, check the set differences';

END IF;

RETURN NULL;

END;
$$ language plpgsql;

CREATE OR REPLACE TRIGGER trigger_af_ins_instance_parent AFTER INSERT ON instance_parent FOR EACH ROW EXECUTE PROCEDURE check_inst_susa_parent();
