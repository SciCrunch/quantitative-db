-- CONNECT TO quantdb_test USER "quantdb-admin";

------------------- handling of datasources

CREATE table objects_internal(
-- TODO ...
id uuid DEFAULT gen_random_uuid() PRIMARY KEY,
label text,
curator_note text
);

CREATE TYPE remote_id_type AS ENUM (
-- FIXME XXX hardcoded remote conventions, essentially an optimization
'organization',
'dataset',
'collection',
'package',  -- XXX we do not currently support packages with multiple files so all packages entered should be to their file level
-- 'file',
-- technically also user is in here
'internal'  -- explicitly not remote (amusingly), TODO see if we want to do it this way ... this should have a foreign key constraint but given that objects are almost always external we pretend that our internal objects table is external, thus no foreign key, the alternative is to add id_interal and then a check constraint, there are other things we probably want in the objects table ... so better
);

CREATE table objects(
-- see sparcur.objects for context on naming, these are effectively datasources that are discrete files
-- yes, technically objects can also have quantiative values "measured" on them, but to avoid having to write CTEs or similar recursive queries, we keep them separate, right now we use the uuid directly as the primary key, at some point we may have to add an additional level of indirection to support multiple object id types, e.g. by identifying them by their checksums instead or something like that
id uuid PRIMARY KEY, -- XXX NOTE this reinforces the fact that we do not support packages with multiple files
id_type remote_id_type NOT NULL,
id_file integer, -- keep this for now to reduce the number of api calls, we may also need/want an s3 path or something
id_internal uuid references objects_internal(id),
constraint constraint_objects_remote_id_type_id_package check ((id_type != 'package') or (id_file is not null)),
constraint constraint_objects_remote_id_type_id_internal check ((id_type != 'internal') or (id_internal is not null and id = id_internal))
);

create table dataset_object(
-- not all objects are associated with a parent dataset
-- but for those that are we need to record the mapping
-- the real structure is hierarchical so a parent table
-- would make the most sense, but we don't need the
-- general case solution right now
dataset_id uuid references objects(id),
object_id uuid references objects(id),
PRIMARY KEY (dataset_id, object_id)
);

------------------- handling of units and aspects of values

create table units(
-- load from either UO or protcur sources
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
-- full unit expression can be composed from prefix + unit
-- or some other unit expression, we won't handle it in here
-- we just want to be able to recover the unit expression
-- use the URI structure or substructure that we already use
-- in sparc to store the unit here, but expect to unpack it
-- as needed
--composed_unit varchar, -- not clear we need this right now
-- unit_expression varchar,
label text,
iri text unique not null
-- if we want to be abel to search over units we will need to enhance this
);

create table aspects(
-- can prepopulate many of these as well
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
label text,
description text,
iri text unique not null
);

------------------- descriptors for instances, categorical, and quantiative values

create table class_measured(
-- FIXME aka inst_descriptors, instanceOf, is_a, subClassOf, etc.
-- the ontology class of the things being measured
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
label text,
description text,
iri text unique not null -- ontology_id,
--real_vs_symbolic, -- site vs roi, subject vs fiber/fascicle
--input_type,
);
--create table inst_descriptors( -- XXX redundant with class_measured, really just a naming issue
---- instance descriptors, used to define in advance where an instance identifier comes from and
---- give a type for how it is extracted, replaces instance_measured_type enum in a more operationally
---- sensible way that is consistent with the other mapping processes
--id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
--is_a integer references class_measured(id), -- yes this looks redundant, with quant_descriptors, but it is used to ensure that instance classes match when things can come from different processes, XXX BIG NOTE: if we are dealing with a heterogenous source, such as say, a hypothetical specimens.xlsx file then an auxillary path specifier may be needed to determine the actual value of class measured
--);

CREATE TYPE cat_range_type AS ENUM (
'open',
'controlled'
);

create table cat_descriptors(
-- otherwise known as predicates, for paralleism with quant
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
is_measuring integer references class_measured(id), -- domain specification, can be loose, but then we can't type check without the ontology
range cat_range_type, -- this is the best we can do for now
label text,
description text,
curator_note text, -- particularly re: mapping
UNIQUE (is_measuring, range, label)
);

CREATE TYPE quant_shape AS ENUM (
'scalar'
);

CREATE TYPE quant_agg_type AS ENUM (
'instance',
'function',
'summary',
'mean',
'media',
'mode',
'sum',
'min',
'max'
);

create table quant_descriptors(
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
shape quant_shape NOT NULL DEFAULT 'scalar', -- do we handle arrays and matricies here, like linkml ndarray issue, some double values e.g. for elipses TODO can we use shape to dispatch to appropriate tables or do we have a values table
unit integer references units(id),  -- mm FK to units
aspect integer references aspects(id),  -- distance, diameter, width
is_measuring integer references class_measured(id), -- class_measured -- points to class_measured measureable_thing -- subject, mouse, sample, cell, neuron, site, electrode, roi, fiber, fasicle -- should be at a higher level, a type of thing, not instances
label text,
description text,
aggregation_type quant_agg_type NOT NULL DEFAULT 'instance', -- FIXME this impaces is_measuring as well
-- TODO if there is anything other than 'instance' in aggregation_type then we would expect
-- the measured_instance to point to a population of instance
curator_note text, -- particularly re: mapping
UNIQUE (unit, aspect, is_measuring, shape, aggregation_type)
);

------------------- instances (owl named individual)

create table sds_specimen( -- FIXME should probably expand to include site, pref, etc.
-- TODO this may need an equivalent id helper table e.g. for cw reva
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
dataset uuid references objects(id), -- FIXME we need a dataset independent version
specimen_id text, -- this is sample or subject sam-123 sub-123
UNIQUE (dataset, specimen_id)
);

create table sds_specimen_equiv(
-- convenience cache of the full bidirectional
-- mapping of specimens that are equivalent to eachother
-- symmetric and transitive
left_thing integer references sds_specimen(id),
right_thing integer references sds_specimen(id),
PRIMARY KEY (left_thing, right_thing),
constraint sse_no_self check (left_thing != right_thing)
);

CREATE OR REPLACE FUNCTION get_all_equivs(new_left_thing integer, new_right_thing integer) RETURNS TABLE (
thing integer -- references sds_specimen(id)
) AS $$
BEGIN

RETURN QUERY
SELECT sse1.left_thing
FROM sds_specimen_equiv AS sse1
WHERE sse1.left_thing = new_left_thing
UNION
SELECT sse2.right_thing
FROM sds_specimen_equiv AS sse2
WHERE sse2.left_thing = new_left_thing
UNION
SELECT sse3.left_thing
FROM sds_specimen_equiv AS sse3
WHERE sse3.left_thing = new_right_thing
UNION
SELECT sse4.right_thing
FROM sds_specimen_equiv AS sse4
WHERE sse4.left_thing = new_right_thing
UNION
SELECT new_left_thing
UNION
SELECT new_right_thing;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION be_ins_sds_spec_expand_equiv() RETURNS trigger as $$ -- FIXME surely this goes on instance measured as well?
BEGIN

-- (a b) will also result in (b a) and that subsequently inserting
-- (c b) -> (b c) (c a) (a c) etc. yes the combinatorics get bad if you

/*
1. get the set of all left right including either of our news
2. take the cartesian product of the individuals to produce all possible pairs
3. add any pairs that are not in existing

you only need to do this for nl and nr appearing as the left thing because we populate the opposite

FIXME the way this is implemented using a before AND an after trigger is an absolute travesty
there is an infinitely better way to do this, but it is not coming to me right now
*/

WITH axis(thing) AS (SELECT * FROM get_all_equivs(NEW.left_thing, NEW.right_thing)),
all_pairs(left_thing, right_thing) AS (SELECT a1.thing, a2.thing FROM axis AS a1, axis AS a2 WHERE a1.thing != a2.thing),
known_pairs(left_thing, right_thing) AS
(
SELECT *
FROM sds_specimen_equiv AS sse
WHERE
sse.left_thing = NEW.left_thing
OR
sse.left_thing = NEW.right_thing
OR
sse.right_thing = NEW.left_thing
OR
sse.right_thing = NEW.right_thing
)
INSERT INTO sds_specimen_equiv (left_thing, right_thing)
SELECT * FROM all_pairs as ap WHERE (ap.left_thing, ap.right_thing) NOT IN (SELECT * FROM known_pairs)
;

RETURN NULL;

END;
$$ language plpgsql;

-- FIXME this is really on instance_measured though ??? or the superset of instance and sds entity?
CREATE OR REPLACE TRIGGER trigger_be_ins_sds_spec_expand_equiv BEFORE INSERT ON sds_specimen_equiv
FOR EACH ROW
WHEN (pg_trigger_depth() = 0)
EXECUTE PROCEDURE be_ins_sds_spec_expand_equiv();

--CREATE TYPE instance_measured_type AS ENUM (
--'sds', -- measurement or derived measure applying to a subject or sample
--'below-sds', -- something below the sds ontology level, e.g. fibers, fascicles
--'lifted-type' -- something below the sds ontology level but lifted, e.g. a gene id implying the rna transcribed for that gene that was extracted from/isolated form in a specific sample inevitably along with the rna for other genes as well
--);

create table instance_measured(
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
-- the exact instance measured, e.g. for fibers it will be the fiber id
-- in a single section, and then also possibly unified later using their
-- common fiber tracking naming algorithm
-- entity_type instance_measured_type, -- gene is a type level that implies "it is the expression of this gene in this context" where the context is implicit
--inst_desc integer references inst_descriptors(id),
inst_desc integer references class_measured(id),
dataset uuid references objects(id), -- FIXME we need a dataset independent version
formal_id text, -- could be same as specimen_id text or something from the sheet
local_identifier text, -- in spreadsheet mapping for the thing, could populate this automatically if we have a way to identify primary keys
--entity_id integer references entity(id),
-- entity_id text unique, -- sub- sam- -- could be iri from ttl file?
--file_row_thing integer,
-- could could have the gene id or similar, multiple levels of context

specimen_id integer references sds_specimen(id), -- always
subject_id integer references sds_specimen(id), -- usually, edge cases are pools/pops
sample_id integer references sds_specimen(id), -- sometimes
UNIQUE (dataset, formal_id)
);

--create table field_mapping(
-- not needed
-- mapping between the raw columns and the curated descriptors
-- what happens if a csv file changes?
-- TODO do we really want this fully normalized
--field,
--quant_desc,
--);

------------------- object to instance mapping

CREATE TYPE field_address_type AS ENUM (
-- FIXME XXX hardcoded remote conventions, essentially an optimization
'tabular-header',
'tabular-alt-header',
'json-path-with-types',  -- XXX only really works in python directly unless we use some convention like 0 or -1 to always imply int
'file-system-extracted',
'arbitrary-function'  -- point to some version controlled source and hope it is a function not a procedure ...
);

create table addresses(
-- this may be an over-normalization, but I think it makes sense, and it will
-- vastly simplify extractions from common metadata files while still supporting
-- the specification for bespoke extractions
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
address_type field_address_type,
field_address text,
curator_note text,
UNIQUE (address_type, field_address) -- XXX this is going to be a pain for anyone inserting, so be sure to use on conflict ignore and return the id
);

create table obj_inst_descriptors(
object_id uuid,
--inst_desc integer references inst_descriptors(id),
inst_desc integer references class_measured(id),  -- FIXME naming
PRIMARY KEY (object_id, inst_desc),
-- TODO right now we aren't abstracting out address_type and address, but those are really what we need
field_address integer references addresses(id) NOT NULL,
class_address integer references addresses(id)
-- transformation from local_id (i.e. field contents) to formal_id is handled outside the db a record might be able to go in prov at some point?
-- this just tells you where to get it and the expected type and format, but doesn't say how those should be transformed
-- but most likely the mapping from local_id to formal_id should be fairly straight forward via the inst_desc table
);

------------------- object to quantitative mapping

create table obj_quant_descriptors(
-- this table is used to map both quantitative and categorical descriptors to package ids
-- this is what needs to be populated and maintained in order to run ingest, and we need
-- to be able to join package to dataset to reduce scope
-- NOTE object_id + quant_desc is sufficient, different fields must always have different descriptors if they contain different values
object_id uuid,
quant_desc integer references quant_descriptors(id), -- quant desc has to be entered first
PRIMARY KEY (object_id, quant_desc),
field_address integer references addresses(id) NOT NULL,
-- XXX at the moment unit_address and aspect_address can only be used as a cross reference check
-- the pre-curation process must have already identified all possible quantiative descriptors
-- even if they are specified in the data, as such unit and aspect are not required
unit_address integer references addresses(id),
aspect_address integer references addresses(id),
class_address integer references addresses(id)
);

------------------- object to categorical mapping

create table obj_cat_descriptors(
-- FIXME the split betweehn quant and cat is annoying, but I'm not sure we can do anything about it right now
-- essentially this is a result of not having a single descriptors table that has a type field and multiple columns
-- which is probably ok ...
object_id uuid,
cat_desc integer references cat_descriptors(id),
PRIMARY KEY (object_id, cat_desc),
field_address integer references addresses(id) NOT NULL,
class_address integer references addresses(id)
);


------------------- prov (old, replaced by object to x mapping)

/*
CREATE TYPE prov_type AS ENUM (
'external-field', -- e.g. from SPARC data file
'internal computation' -- e.g. a complex select statement
);

create table provenance(
-- 
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
type prov_type, -- this control the interpretation of the field source
field_name text, -- XXX no longer has meaning since we are using obj_quant_desc
field_source text, -- file path ??? pennsieve package id + dataset id  # XXX need to invert so that esra can get all measurements associated with a given file
-- field_source_source, -- TODO for the original image something was extracted from
-- XXX field source being file path implies sds entity id
obj_inst_desc integer references obj_inst_descriptors(id), -- this may seem like overkill, but it ensures that we have an explicit checkpoint where everything can be checked to ensure that classes, domain, range, etc. match before we pull out the value and stick it in the requisite table
obj_quant_desc integer references obj_quant_descriptors(id), -- quant desc has to be entered first
obj_cat_desc integer references obj_cat_descriptors(id),
constraint constraint_provenance_quant_or_cat check ((obj_quant_desc is not null or obj_cat_desc is not null) and not (obj_quant_desc is not null and obj_cat_desc is not null)) -- FIXME as written this only applies to the external-field case
);
-- if we want to use this to describe internal computations
-- field_name is the defined column name that the query returns
-- field_source is a query over quant_values or some join including it
-- quant_desc is the quant descriptor that is the output
*/

/*
create table interal_computation(
id,
query,
resulting_value,
resulting_units,
);
*/

-- two processes
-- 1 mapping of tabular schema "precuration" initially just in inserts.sql
-- 2 ingest
-- during mapping there are cases where we will need to map columns
-- to input instance metadata in addition to quant_values, specifically
-- for gene ids, this is context living inside vs outside the source file

-- how to deal with gene expression levels, don't really want a descriptor per gene

-- what are measured instances
-- mouse that has subject id
-- gene expression from a sample where there are 23k values
-- fiber diameter identified in one section vs across sections (becomes gene)

------------------- quantiative values

create table quant_values( -- atomic scalar values
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
--units varchar NOT NULL,
--aspect varchar NOT NULL, -- XXX vs metric
--input varchar NOT NULL,
--input_type , -- real or symbolic, site or roi etc.
--input_or_symbolic , --
-- FIXME categorical value ...
value numeric NOT NULL, -- FIXME might be an array or something? mostly present

object_id uuid references objects(id),
inst_desc integer references class_measured(id),
quant_desc integer references quant_descriptors(id),  -- quant_desciptors id FIXME redundant with prov, but useful to simplify joins and for validation

FOREIGN KEY (object_id, inst_desc) REFERENCES obj_inst_descriptors (object_id, inst_desc),
FOREIGN KEY (object_id, quant_desc) REFERENCES obj_quant_descriptors (object_id, quant_desc),

measured_instance integer references instance_measured(id), -- instance_measured id -- links simliar measures on the same input (row)


orig_value varchar,
orig_units varchar,
-- FIXME TODO may also need original_type if such information was tracked
value_blob jsonb NOT NULL -- a full json represntation that may have weird shapes
-- UNIQUE (quant_desc, prov, measured_instance), -- FIXME issues with repeated measures? issues with values
);

-- TODO categorical values table over measured instances
-- can we also use categorical values to store relations to transitive samples, subjects, datasets, etc.

------------------- categorical values

create table controlled_terms(
-- this is kept separate from class_measured because class measured has stronger semantics
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
label text,
iri text unique not null
);

create table cat_values( -- categorical values
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
value_open text NOT NULL, -- always equivalent to orig_value
value_controlled integer references controlled_terms(id),

object_id uuid references objects(id),
inst_desc integer references class_measured(id),
cat_desc integer references cat_descriptors(id),

FOREIGN KEY (object_id, inst_desc) REFERENCES obj_inst_descriptors (object_id, inst_desc),
FOREIGN KEY (object_id, cat_desc) REFERENCES obj_cat_descriptors (object_id, cat_desc),

measured_instance integer references instance_measured(id) -- instance_measured id -- links simliar measures on the same input (row)

);
