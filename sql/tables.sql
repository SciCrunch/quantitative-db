-- CONNECT TO quantdb_test USER "quantdb-admin";

------------------- handling of datasources

CREATE TYPE oi_type AS ENUM (
'path-metadata',
'other'
);

CREATE table objects_internal(
-- TODO ...
id uuid DEFAULT gen_random_uuid() PRIMARY KEY,
type oi_type DEFAULT 'other',
dataset uuid,
updated_transitive timestamp,
label text,
curator_note text,
unique (dataset, updated_transitive),
constraint constraint_objects_internal_type_updated_transitive check (type != 'path-metadata' or (updated_transitive is not null and dataset is not null))
);

CREATE TYPE remote_id_type AS ENUM (
-- FIXME XXX hardcoded remote conventions, essentially an optimization
'organization',
'dataset',
'collection',
'package',  -- XXX we do not currently support packages with multiple files so all packages entered should be to their file level
-- 'file',
-- technically also user is in here
'internal'  -- explicitly not remote (amusingly), TODO see if we want to do it this way ... this should have a foreign key constraint but given that objects are almost always external we pretend that our internal objects table is external, thus no foreign key, the alternative is to add id_interal and then a check constraint, there are other things we probably want in the objects table ... so better
);

CREATE table objects(
-- see sparcur.objects for context on naming, these are effectively datasources that are discrete files
-- yes, technically objects can also have quantiative values "measured" on them, but to avoid having to write CTEs or similar recursive queries, we keep them separate, right now we use the uuid directly as the primary key, at some point we may have to add an additional level of indirection to support multiple object id types, e.g. by identifying them by their checksums instead or something like that
id uuid PRIMARY KEY, -- XXX NOTE this reinforces the fact that we do not support packages with multiple files
id_type remote_id_type NOT NULL,
id_file integer, -- keep this for now to reduce the number of api calls, we may also need/want an s3 path or something
id_internal uuid references objects_internal(id),
constraint constraint_objects_remote_id_type_id_package check ((id_type != 'package') or (id_file is not null)),
constraint constraint_objects_remote_id_type_id_internal check ((id_type != 'internal') or (id_internal is not null and id = id_internal))
);

ALTER table objects_internal ADD constraint constraint_oi_dataset_fk FOREIGN KEY (dataset) references objects(id);

create table dataset_object(
-- not all objects are associated with a parent dataset
-- but for those that are we need to record the mapping
-- the real structure is hierarchical so a parent table
-- would make the most sense, but we don't need the
-- general case solution right now
dataset_id uuid references objects(id),
object_id uuid references objects(id),
PRIMARY KEY (dataset_id, object_id)
);

------------------- handling of units and aspects of values

create table units(
-- load from either UO or protcur sources
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
-- full unit expression can be composed from prefix + unit
-- or some other unit expression, we won't handle it in here
-- we just want to be able to recover the unit expression
-- use the URI structure or substructure that we already use
-- in sparc to store the unit here, but expect to unpack it
-- as needed
--composed_unit varchar, -- not clear we need this right now
-- unit_expression varchar,
label text,
iri text unique not null
-- if we want to be abel to search over units we will need to enhance this
);

create table aspects(
-- can prepopulate many of these as well
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
label text,
description text,
iri text unique not null
);

------------------- descriptors for instances, categorical, and quantiative values

create table class_measured(
-- FIXME aka inst_descriptors, instanceOf, is_a, subClassOf, etc.
-- the ontology class of the things being measured
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
label text,
description text,
iri text unique not null -- ontology_id,
--real_vs_symbolic, -- site vs roi, subject vs fiber/fascicle
--input_type,
);
--create table inst_descriptors( -- XXX redundant with class_measured, really just a naming issue
---- instance descriptors, used to define in advance where an instance identifier comes from and
---- give a type for how it is extracted, replaces instance_measured_type enum in a more operationally
---- sensible way that is consistent with the other mapping processes
--id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
--is_a integer references class_measured(id), -- yes this looks redundant, with quant_descriptors, but it is used to ensure that instance classes match when things can come from different processes, XXX BIG NOTE: if we are dealing with a heterogenous source, such as say, a hypothetical specimens.xlsx file then an auxillary path specifier may be needed to determine the actual value of class measured
--);

CREATE TYPE cat_range_type AS ENUM (
'open',
'controlled'
);

create table cat_descriptors(
-- otherwise known as predicates, for paralleism with quant
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
is_measuring integer references class_measured(id), -- domain specification, can be loose, but then we can't type check without the ontology
range cat_range_type, -- this is the best we can do for now
label text,
description text,
curator_note text, -- particularly re: mapping
UNIQUE (is_measuring, range, label)
);

CREATE TYPE quant_shape AS ENUM (
'scalar'
);

CREATE TYPE quant_agg_type AS ENUM (
'instance',
'function',
'summary',
'mean',
'media',
'mode',
'sum',
'min',
'max'
);

create table quant_descriptors(
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
shape quant_shape NOT NULL DEFAULT 'scalar', -- do we handle arrays and matricies here, like linkml ndarray issue, some double values e.g. for elipses TODO can we use shape to dispatch to appropriate tables or do we have a values table
unit integer references units(id),  -- mm FK to units
aspect integer references aspects(id),  -- distance, diameter, width
is_measuring integer references class_measured(id), -- class_measured -- points to class_measured measureable_thing -- subject, mouse, sample, cell, neuron, site, electrode, roi, fiber, fasicle -- should be at a higher level, a type of thing, not instances
label text unique not null, -- 99% of the time this is going to be used for retrieval so unn it
description text,
aggregation_type quant_agg_type NOT NULL DEFAULT 'instance', -- FIXME this impaces is_measuring as well
-- TODO if there is anything other than 'instance' in aggregation_type then we would expect
-- the measured_instance to point to a population of instance
curator_note text, -- particularly re: mapping
UNIQUE (unit, aspect, is_measuring, shape, aggregation_type)
);

------------------- instances (owl named individual)

/*
create table sds_specimen( -- FIXME should probably expand to include site, pref, etc.
-- TODO this may need an equivalent id helper table e.g. for cw reva
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
dataset uuid references objects(id), -- FIXME we need a dataset independent version
specimen_id text, -- this is sample or subject sam-123 sub-123
-- parent_id integer references sds_specimen(id), -- do not do this in this way because it forces an order dependency when loading data
UNIQUE (dataset, specimen_id)
);
*/

CREATE TYPE instance_type AS ENUM (
-- instance_type is needed in addition to instance_class because we only allow a single class for an instance
-- however we also need to be able to identify entities that map directly to sds entities (for now just subject
-- and sample) without having to parse ids or guess
'subject',
'sample',
'below' -- entities that might be part of a sample but were not derived from it during the experiment
--'performance',
--'lifted-type' -- something below the sds ontology level but lifted, e.g. a gene id implying the rna transcribed for that gene that was extracted from/isolated form in a specific sample inevitably along with the rna for other genes as well
);

create table instance_measured(
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
-- the exact instance measured, e.g. for fibers it will be the fiber id
-- in a single section, and then also possibly unified later using their
-- common fiber tracking naming algorithm
-- entity_type instance_measured_type, -- gene is a type level that implies "it is the expression of this gene in this context" where the context is implicit
--inst_desc integer references inst_descriptors(id),
type instance_type NOT NULL,
inst_desc integer references class_measured(id),
dataset uuid references objects(id), -- FIXME we need a dataset independent version
formal_id text, -- could be same as specimen_id text or something from the sheet, if we are ingesting a whole file as a virtual section the id would be the file path, but idealy it would be the sample
local_identifier text, -- in spreadsheet mapping for the thing, could populate this automatically if we have a way to identify primary keys
--entity_id integer references entity(id),
-- entity_id text unique, -- sub- sam- -- could be iri from ttl file?
--file_row_thing integer,
-- could could have the gene id or similar, multiple levels of context

-- these can still be checked against the parent table and if we are using a trigger to check references, these can both be checked in one go
-- XXX we could, but choose not to enforce a foreign key on dataset and sub_id mapping to instance measured at this point
sub_id text check (sub_id ~ '^sub-'), -- alternative to instance_subject FIXME should be require this even if type is subject for closure?
sam_id text check (sam_id ~ '^sam-'), -- alternative to instance_sample

-- FIXME TODO replace with parent
-- NOTE re: jgrethe comment: since we are moving to have a single instance_measured table we want to avoid self reference foreign keys because it introduces an implicit order dependency, instead we will have a separate table beyond just the parent table so that we can insert without self reference, or something like that
--specimen_id integer references sds_specimen(id) NOT NULL, -- always
--subject_id integer references sds_specimen(id) NOT NULL, -- usually, edge cases are pools/pops XXX not null this for now and see what happens
--sample_id integer references sds_specimen(id), -- sometimes
UNIQUE (dataset, formal_id),
constraint constraint_instance_measured_type_formal_id check (type = 'below' and not (formal_id ~ '^(sub|sam)-') or type = 'subject' and formal_id ~ '^sub-' or type = 'sample' and formal_id ~ '^sam-'),
constraint constraint_instance_measured_type_sub_id check ((type = 'subject') or (sub_id is not null)), -- FIXME cases where a cell line is the subject are going to confuse people, welcome to names not matching their meaning
constraint constraint_instance_measured_type_below check (type <> 'below' or type = 'below' and (sub_id is not null or sam_id is not null)) -- XXX there is not a general way to enforce that there must be a sample, e.g. a mri experiment can have virtual of sections of the brain without there being samples in the dataset at all, only subjects and performances
);

/*
create table instance_subject(
id integer references instance_measured(id),
subject integer references instance_measured(id),
PRIMARY KEY (id, subject)
);

CREATE OR REPLACE FUNCTION check_subject_is_subject() RETURNS trigger as $$
BEGIN
-- TODO may also want to check that the dataset ids match for sanity's sake
IF EXISTS (SELECT type FROM instance_measured WHERE id = NEW.subject AND type = 'subject') THEN
RETURN NEW;
ELSE
RAISE EXCEPTION 'subject instance is not of type subject: %', (SELECT type FROM instance_measured WHERE id = NEW.subject)
USING HINT = 'the instance_measured referenced as a subject must have type subject';
END IF;
END;
$$ language plpgsql;

CREATE OR REPLACE TRIGGER trigger_be_ins_inst_sub BEFORE INSERT ON instance_subject FOR EACH ROW EXECUTE PROCEDURE check_subject_is_subject();

create table instance_sample(
id integer references instance_measured(id),
sample integer references instance_measured(id),
PRIMARY KEY (id, sample)
);

CREATE OR REPLACE FUNCTION check_sample_is_sample() RETURNS trigger as $$
BEGIN
-- TODO may also want to check that the dataset ids match for sanity's sake
IF EXISTS (SELECT type FROM instance_measured WHERE id = NEW.sample AND type = 'sample') THEN
RETURN NEW;
ELSE
RAISE EXCEPTION 'sample instance is not of type sample: %', (SELECT type FROM instance_measured WHERE id = NEW.sample)
USING HINT = 'the instance_measured referenced as a sample must have type sample';
END IF;
END;
$$ language plpgsql;

CREATE OR REPLACE TRIGGER trigger_be_ins_inst_sam BEFORE INSERT ON instance_sample FOR EACH ROW EXECUTE PROCEDURE check_sample_is_sample();
*/

create table inst_equiv(
-- convenience cache of the full bidirectional
-- mapping of specimens that are equivalent to eachother
-- symmetric and transitive
left_thing integer references instance_measured(id),
right_thing integer references instance_measured(id),
PRIMARY KEY (left_thing, right_thing),
constraint sse_no_self check (left_thing != right_thing)
);

CREATE OR REPLACE FUNCTION get_all_equivs(new_left_thing integer, new_right_thing integer) RETURNS TABLE (
thing integer -- references sds_specimen(id)
) AS $$
BEGIN

RETURN QUERY
SELECT sse1.left_thing
FROM inst_equiv AS sse1
WHERE sse1.left_thing = new_left_thing
UNION
SELECT sse2.right_thing
FROM inst_equiv AS sse2
WHERE sse2.left_thing = new_left_thing
UNION
SELECT sse3.left_thing
FROM inst_equiv AS sse3
WHERE sse3.left_thing = new_right_thing
UNION
SELECT sse4.right_thing
FROM inst_equiv AS sse4
WHERE sse4.left_thing = new_right_thing
UNION
SELECT new_left_thing
UNION
SELECT new_right_thing;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION be_ins_sds_spec_expand_equiv() RETURNS trigger as $$ -- FIXME surely this goes on instance measured as well?
BEGIN

-- (a b) will also result in (b a) and that subsequently inserting
-- (c b) -> (b c) (c a) (a c) etc. yes the combinatorics get bad if you

/*
1. get the set of all left right including either of our news
2. take the cartesian product of the individuals to produce all possible pairs
3. add any pairs that are not in existing

you only need to do this for nl and nr appearing as the left thing because we populate the opposite

FIXME the way this is implemented using a before AND an after trigger is an absolute travesty
there is an infinitely better way to do this, but it is not coming to me right now
*/

WITH axis(thing) AS (SELECT * FROM get_all_equivs(NEW.left_thing, NEW.right_thing)),
all_pairs(left_thing, right_thing) AS (SELECT a1.thing, a2.thing FROM axis AS a1, axis AS a2 WHERE a1.thing != a2.thing),
known_pairs(left_thing, right_thing) AS
(
SELECT *
FROM inst_equiv AS sse
WHERE
sse.left_thing = NEW.left_thing
OR
sse.left_thing = NEW.right_thing
OR
sse.right_thing = NEW.left_thing
OR
sse.right_thing = NEW.right_thing
)
INSERT INTO inst_equiv (left_thing, right_thing)
SELECT * FROM all_pairs as ap WHERE (ap.left_thing, ap.right_thing) NOT IN (SELECT * FROM known_pairs)
;

RETURN NULL;

END;
$$ language plpgsql;

-- FIXME this is really on instance_measured though ??? or the superset of instance and sds entity?
CREATE OR REPLACE TRIGGER trigger_be_ins_sds_spec_expand_equiv BEFORE INSERT ON inst_equiv
FOR EACH ROW
WHEN (pg_trigger_depth() = 0)
EXECUTE PROCEDURE be_ins_sds_spec_expand_equiv();

------------------- support for hierarchical relations
-- all the major types we deal with, instances, classes, and aspects have arbitrary transitive parent relations that are really what we want to query over to get things like subject_id, sample_id, etc. so just implement it

create table class_parent(
id integer references class_measured(id),
parent integer references class_measured(id),
PRIMARY KEY (id, parent)
);

-- single parent hierarchies for our major types
create table instance_parent( -- FIXME TODO really, merge instances with sds entities this with
id integer references instance_measured(id),
parent integer references instance_measured(id),
PRIMARY KEY (id, parent)
);

create table aspect_parent(
id integer references aspects(id),
parent integer references aspects(id),
PRIMARY KEY (id, parent)
);

------------------- object to instance mapping

CREATE TYPE field_value_type AS ENUM (
'single',
'multi' -- FIXME this is actually maybe-multi ...
);

CREATE TYPE field_address_type AS ENUM (
-- FIXME XXX hardcoded remote conventions, essentially an optimization
'tabular-header',
'tabular-alt-header',

'workbook-sheet-tabular-header',  -- DO NOT WANT
'workbook-sheet-tabular-alt-header',  -- DO NOT WANT

'json-path-with-types',  -- XXX only really works in python directly unless we use some convention like 0 or -1 to always imply int
'file-system-extracted',
'arbitrary-function'  -- point to some version controlled source and hope it is a function not a procedure ...
);

create table addresses(
-- this may be an over-normalization, but I think it makes sense, and it will
-- vastly simplify extractions from common metadata files while still supporting
-- the specification for bespoke extractions
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
address_type field_address_type,
value_type field_value_type DEFAULT 'single', -- FIXME not 100% on whether this is necessary, I think it is
field_address text,
curator_note text,
UNIQUE (address_type, field_address, value_type) -- XXX this is going to be a pain for anyone inserting, so be sure to use on conflict ignore and return the id
);

create table obj_inst_descriptors(
-- TODO the workflow for ingestion is to query these obj_x_descriptors tables and find cases where there are no assicated values of any kind and then run the ingest for those files
object_id uuid references objects(id), -- FIXME shouldn't this be unique? and the primary key? so we can do FK instead of the trigger below? maybe not? maybe there are objects that have, e.g. multiple data tables inside them or complex json that has multiple types? (sigh yeah that could get messy and might cause a proliferation of class_measured, or indicate insane data (lack of) organization)
--inst_desc integer references inst_descriptors(id),
inst_desc integer references class_measured(id),  -- FIXME naming
PRIMARY KEY (object_id, inst_desc),
-- TODO right now we aren't abstracting out address_type and address, but those are really what we need
field_address integer references addresses(id) NOT NULL,
class_address integer references addresses(id)
-- transformation from local_id (i.e. field contents) to formal_id is handled outside the db a record might be able to go in prov at some point?
-- this just tells you where to get it and the expected type and format, but doesn't say how those should be transformed
-- but most likely the mapping from local_id to formal_id should be fairly straight forward via the inst_desc table
);

CREATE OR REPLACE FUNCTION check_inst_desc_exists() RETURNS trigger as $$
BEGIN

IF EXISTS (SELECT FROM obj_inst_descriptors WHERE NEW.object_id = object_id) THEN
RETURN NEW;
ELSE
RAISE EXCEPTION 'object_id not in obj_inst_descriptors: %', NEW.object_id
USING HINT = 'object instance descriptor mappings should always be inserted first';
END IF;

END;
$$ language plpgsql;

------------------- object to quantitative mapping

create table obj_quant_descriptors(
-- this table is used to map both quantitative and categorical descriptors to package ids
-- this is what needs to be populated and maintained in order to run ingest, and we need
-- to be able to join package to dataset to reduce scope
-- NOTE object_id + quant_desc is sufficient, different fields must always have different descriptors if they contain different values
object_id uuid references objects(id),
quant_desc integer references quant_descriptors(id), -- quant desc has to be entered first
PRIMARY KEY (object_id, quant_desc),
field_address integer references addresses(id) NOT NULL,
-- XXX at the moment unit_address and aspect_address can only be used as a cross reference check
-- the pre-curation process must have already identified all possible quantiative descriptors
-- even if they are specified in the data, as such unit and aspect are not required
unit_address integer references addresses(id),
aspect_address integer references addresses(id),
class_address integer references addresses(id) -- FIXME does this actually go here? different name?
);

CREATE OR REPLACE TRIGGER trigger_be_ins_obj_quant_desc BEFORE INSERT ON obj_quant_descriptors FOR EACH ROW EXECUTE PROCEDURE check_inst_desc_exists();

------------------- object to categorical mapping

create table obj_cat_descriptors(
-- FIXME the split betweehn quant and cat is annoying, but I'm not sure we can do anything about it right now
-- essentially this is a result of not having a single descriptors table that has a type field and multiple columns
-- which is probably ok ...
object_id uuid references objects(id),
cat_desc integer references cat_descriptors(id),
PRIMARY KEY (object_id, cat_desc),
field_address integer references addresses(id) NOT NULL,
class_address integer references addresses(id) -- FIXME does this actually go here? different name?
);

CREATE OR REPLACE TRIGGER trigger_be_ins_obj_cat_desc BEFORE INSERT ON obj_cat_descriptors FOR EACH ROW EXECUTE PROCEDURE check_inst_desc_exists();

------------------- prov (old, replaced by object to x mapping)

/*
CREATE TYPE prov_type AS ENUM (
'external-field', -- e.g. from SPARC data file
'internal computation' -- e.g. a complex select statement
);

create table provenance(
-- 
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
type prov_type, -- this control the interpretation of the field source
field_name text, -- XXX no longer has meaning since we are using obj_quant_desc
field_source text, -- file path ??? pennsieve package id + dataset id  # XXX need to invert so that esra can get all measurements associated with a given file
-- field_source_source, -- TODO for the original image something was extracted from
-- XXX field source being file path implies sds entity id
obj_inst_desc integer references obj_inst_descriptors(id), -- this may seem like overkill, but it ensures that we have an explicit checkpoint where everything can be checked to ensure that classes, domain, range, etc. match before we pull out the value and stick it in the requisite table
obj_quant_desc integer references obj_quant_descriptors(id), -- quant desc has to be entered first
obj_cat_desc integer references obj_cat_descriptors(id),
constraint constraint_provenance_quant_or_cat check ((obj_quant_desc is not null or obj_cat_desc is not null) and not (obj_quant_desc is not null and obj_cat_desc is not null)) -- FIXME as written this only applies to the external-field case
);
-- if we want to use this to describe internal computations
-- field_name is the defined column name that the query returns
-- field_source is a query over quant_values or some join including it
-- quant_desc is the quant descriptor that is the output
*/

/*
create table interal_computation(
id,
query,
resulting_value,
resulting_units,
);
*/

-- two processes
-- 1 mapping of tabular schema "precuration" initially just in inserts.sql
-- 2 ingest
-- during mapping there are cases where we will need to map columns
-- to input instance metadata in addition to quant_values, specifically
-- for gene ids, this is context living inside vs outside the source file

-- how to deal with gene expression levels, don't really want a descriptor per gene

-- what are measured instances
-- mouse that has subject id
-- gene expression from a sample where there are 23k values
-- fiber diameter identified in one section vs across sections (becomes gene)

------------------- quantiative values

create table quant_values( -- atomic scalar values
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
--units varchar NOT NULL,
--aspect varchar NOT NULL, -- XXX vs metric
--input varchar NOT NULL,
--input_type , -- real or symbolic, site or roi etc.
--input_or_symbolic , --
-- FIXME categorical value ...
value numeric NOT NULL, -- FIXME might be an array or something? mostly present

object_id uuid references objects(id) NOT NULL,
inst_desc integer references class_measured(id) NOT NULL,
quant_desc integer references quant_descriptors(id) NOT NULL,  -- quant_desciptors id FIXME redundant with prov, but useful to simplify joins and for validation

FOREIGN KEY (object_id, inst_desc) REFERENCES obj_inst_descriptors (object_id, inst_desc),
FOREIGN KEY (object_id, quant_desc) REFERENCES obj_quant_descriptors (object_id, quant_desc),

measured_instance integer references instance_measured(id), -- instance_measured id -- links simliar measures on the same input (row)

orig_value varchar,
orig_units varchar,
-- FIXME TODO may also need original_type if such information was tracked
value_blob jsonb NOT NULL -- a full json represntation that may have weird shapes
-- UNIQUE (quant_desc, prov, measured_instance), -- FIXME issues with repeated measures? issues with values
);

-- TODO categorical values table over measured instances
-- can we also use categorical values to store relations to transitive samples, subjects, datasets, etc.

------------------- categorical values

create table controlled_terms(
-- this is kept separate from class_measured because class measured has stronger semantics
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
label text,
iri text unique not null
);

create table cat_values( -- categorical values
id integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
value_open text NOT NULL, -- always equivalent to orig_value TODO may want this nullable due to the bottom case ... ?? nah always want something
value_controlled integer references controlled_terms(id),

object_id uuid references objects(id) NOT NULL,
inst_desc integer references class_measured(id) NOT NULL,
cat_desc integer references cat_descriptors(id) NOT NULL,

FOREIGN KEY (object_id, inst_desc) REFERENCES obj_inst_descriptors (object_id, inst_desc),
FOREIGN KEY (object_id, cat_desc) REFERENCES obj_cat_descriptors (object_id, cat_desc),

measured_instance integer references instance_measured(id) -- instance_measured id -- links simliar measures on the same input (row)

);

------------------- convenience functions

CREATE OR REPLACE FUNCTION left_and_right_n(string text, n integer, OUT ret text) AS $$
BEGIN
SELECT LEFT(string, n) || ' ... ' || RIGHT(string, n) INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION object_internal_from_dataset_updated_transitive(in_dataset uuid, in_updated_transitive timestamp, OUT ret uuid) AS $$
BEGIN
SELECT id FROM objects_internal WHERE dataset = in_dataset AND updated_transitive = in_updated_transitive INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION unit_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM units WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION aspect_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM aspects WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION inst_desc_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM class_measured WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION cterm_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM controlled_terms WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION quant_desc_from_label(in_label text, OUT ret integer) AS $$
BEGIN
SELECT id FROM quant_descriptors WHERE label = in_label INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION cat_desc_from_label_measuring_label(in_label text, in_is_measuring_label text, OUT ret integer) AS $$
BEGIN
IF in_is_measuring_label IS NULL THEN
SELECT id FROM cat_descriptors WHERE label = in_label INTO ret;
ELSE
SELECT id FROM cat_descriptors WHERE label = in_label AND is_measuring = inst_desc_from_label(in_is_measuring_label) INTO ret;
END IF;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION inst_from_dataset_id(in_dataset uuid, in_formal_id text, OUT ret integer) AS $$
BEGIN
SELECT id FROM instance_measured WHERE dataset = in_dataset AND formal_id = in_formal_id INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION insts_from_dataset_ids(in_dataset uuid, in_formal_ids text[]) RETURNS TABLE(id integer, dataset uuid, formal_id text) AS $$
-- TODO this is the best we can do without having to deal with an array of pairs
-- since our unit of work is usually a single dataset this is probably ok
BEGIN
RETURN QUERY
SELECT im.id, im.dataset, im.formal_id FROM instance_measured as im WHERE im.dataset = in_dataset AND im.formal_id = ANY (in_formal_ids);
END;
$$ language plpgsql;

/*
CREATE OR REPLACE FUNCTION spec_from_dataset_id(in_dataset uuid, in_specimen_id text, OUT ret integer) AS $$
BEGIN
SELECT id FROM sds_specimen WHERE dataset = in_dataset AND specimen_id = in_specimen_id INTO ret;
END;
$$ language plpgsql;
*/

CREATE OR REPLACE FUNCTION address_from_fadd_type_fadd(in_fadd_type field_address_type, in_fadd text, OUT ret integer) AS $$
BEGIN
IF in_fadd IS NULL THEN
SELECT id FROM addresses WHERE address_type = in_fadd_type AND field_address IS NULL INTO ret;
ELSE
SELECT id FROM addresses WHERE address_type = in_fadd_type AND field_address = in_fadd INTO ret;
END IF;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION address_from_fadd_type_fadd_vtype(in_fadd_type field_address_type, in_fadd text, in_vtype field_value_type, OUT ret integer) AS $$
BEGIN
/* -- bad footgun, don't do this
IF in_vtype IS NULL THEN
vtype := 'single';
ELSE
vtype := in_vtype;
END IF;
*/
SELECT id FROM addresses WHERE address_type = in_fadd_type AND field_address = in_fadd AND value_type = in_vtype INTO ret;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_unextracte_objects() RETURNS TABLE(id_type remote_id_type, id uuid) AS $$
BEGIN

RETURN QUERY
-- more granular query to get object ids where cat or quant data have not
-- been extracted for the specific descriptors that have been specified
-- this makes it possible to do incremental extraction
SELECT objects.id_type, oqd.object_id FROM obj_quant_descriptors AS oqd
LEFT JOIN quant_values as qv
ON oqd.object_id = qv.object_id AND oqd.quant_desc = qv.quant_desc
JOIN objects ON oqd.object_id = objects.id
WHERE qv.object_id IS NULL OR qv.quant_desc IS NULL

UNION

SELECT objects.id_type, ocd.object_id FROM obj_cat_descriptors AS ocd
-- FIXME this can't detect cases where an UPDATE modified a cat_desc address value type or changed an address
-- e.g. if a curator makes a mistake, I guess we can have a force rerun option or add an AFTER UPDATE trigger
-- the obj_x_descriptor tables ??
LEFT JOIN cat_values as cv
ON ocd.object_id = cv.object_id AND ocd.cat_desc = cv.cat_desc
JOIN objects ON ocd.object_id = objects.id
WHERE cv.object_id IS NULL OR cv.cat_desc IS NULL;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_all_values_example() RETURNS TABLE(
value numeric,
value_open text,
value_controlled text,
unit_o_range text,
aspect_o_pred text,
agg_type quant_agg_type,
inst_desc text, -- aka owl:Class
formal_id text,
sample_id text,
subject_id text,
dset text,
obj text
) AS $$
BEGIN

RETURN QUERY

SELECT qv.value, NULL as open, NULL as controlled, u.label, a.label, qd.aggregation_type, id.label, im.formal_id, saim.formal_id, suim.formal_id, left_and_right_n(im.dataset::text, 4), left_and_right_n(qv.object_id::text, 4) FROM quant_values AS qv
JOIN quant_descriptors AS qd ON qv.quant_desc = qd.id
LEFT OUTER JOIN units AS u ON qd.unit = u.id -- loj because unitless is represented as null for now ?
JOIN aspects AS a ON qd.aspect = a.id
JOIN class_measured AS id ON qv.inst_desc = id.id
JOIN instance_measured AS im ON qv.measured_instance = im.id

JOIN instance_measured AS suim ON im.dataset = suim.dataset AND im.sub_id = suim.formal_id
LEFT OUTER JOIN instance_measured AS saim ON im.dataset = saim.dataset AND im.sam_id = saim.formal_id -- loj since this sam_id is nullable

UNION

SELECT NULL, cv.value_open, ct.label, cd.range::text, cd.label, NULL, id.label, im.formal_id, saim.formal_id, suim.formal_id, left_and_right_n(im.dataset::text, 4), left_and_right_n(cv.object_id::text, 4) FROM cat_values AS cv
JOIN controlled_terms AS ct ON cv.value_controlled = ct.id
JOIN cat_descriptors AS cd ON cv.cat_desc = cd.id
JOIN class_measured AS id ON cv.inst_desc = id.id
JOIN instance_measured AS im ON cv.measured_instance = im.id

JOIN instance_measured AS suim ON im.dataset = suim.dataset AND im.sub_id = suim.formal_id
LEFT OUTER JOIN instance_measured AS saim ON im.dataset = saim.dataset AND im.sam_id = saim.formal_id -- loj since this sam_id is nullable

;

END;
$$ language plpgsql;

------------------- functions for hierarchies
-- we may ultimately use these in triggers or something to materialize e.g. subject_id into records
-- we might also use them as a cross reference check and still require subject_id to be present
-- for measured instances

-------- aspects

CREATE OR REPLACE FUNCTION get_aspect_children(id_aspect_start integer) RETURNS TABLE (
child integer
) AS $$
-- single transitive children list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT ap0.id FROM aspect_parent AS ap0 WHERE ap0.parent = id_aspect_start
UNION ALL
SELECT ap.id
FROM aspect_parent AS ap
JOIN tree AS t ON ap.parent = t.id
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_aspect_child_edges(id_aspect_start integer) RETURNS TABLE (
parent integer,
child integer
) AS $$
-- lift transitive edges to direct
-- TODO for this to be differentially useful it would take multiple parents as an argument ... ???
BEGIN
RETURN QUERY
WITH RECURSIVE tree(parent, child) AS (
--SELECT ap0.parent, id FROM aspect_parent AS ap0 WHERE ap0.parent = id_aspect_start
SELECT id_aspect_start, id FROM aspect_parent AS ap0 WHERE ap0.parent = id_aspect_start
UNION ALL
--SELECT ap.parent, ap.id
SELECT id_aspect_start, ap.id
FROM aspect_parent AS ap
JOIN tree AS t ON ap.parent = t.child
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_aspect_parents(id_aspect_start integer) RETURNS TABLE (
parent integer
) AS $$
-- single transitive parent list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT ap0.parent FROM aspect_parent AS ap0 WHERE id = id_aspect_start
UNION ALL
SELECT ap.parent
FROM aspect_parent AS ap
JOIN tree AS t ON ap.id = t.id
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_aspect_parent_edges(id_aspect_start integer) RETURNS TABLE (
child integer,
parent integer
) AS $$
-- a slightly easier to read version that returns the edges
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parent) AS (
SELECT id, ap0.parent FROM aspect_parent AS ap0 WHERE id = id_aspect_start
UNION ALL
SELECT ap.id, ap.parent
FROM aspect_parent AS ap
JOIN tree AS t ON ap.id = t.parent
)
SELECT * FROM tree;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_all_aspect_parents() RETURNS TABLE (
id integer,
parents integer[]
) AS $$
-- a version that will generate the transitive parents for all records
-- for this it is better to populate top down
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parents) AS (
SELECT parent, ARRAY[]::integer[] FROM -- start from nodes with no parents
(SELECT ap0.parent FROM aspect_parent AS ap0 EXCEPT SELECT ap1.id FROM aspect_parent AS ap1)
UNION ALL
SELECT ap.id, ap.parent || t.parents
FROM aspect_parent AS ap
JOIN tree AS t ON ap.parent = t.child
)
SELECT * FROM tree;

END;
$$ language plpgsql;

-- TODO if we do not materialize the value we need into the child records
-- which is definitely the case for aspects and classes, then we also need
-- the inverse queries that return all children so that we can expand down
-- OR we populate giant cartesian tables to be used in joins

-------- classes

CREATE OR REPLACE FUNCTION get_class_children(id_class_start integer) RETURNS TABLE (
child integer
) AS $$
-- single transitive children list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT cp0.id FROM class_parent AS cp0 WHERE cp0.parent = id_class_start
UNION ALL
SELECT cp.id
FROM class_parent AS cp
JOIN tree AS t ON cp.parent = t.id
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_class_parents(id_class_start integer) RETURNS TABLE (
parent integer
) AS $$
-- single transitive parent list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT cp0.parent FROM class_parent AS cp0 WHERE id = id_class_start
UNION ALL
SELECT cp.parent
FROM class_parent AS cp
JOIN tree AS t ON cp.id = t.id
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_class_parent_edges(id_class_start integer) RETURNS TABLE (
child integer,
parent integer
) AS $$
-- a slightly easier to read version that returns the edges
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parent) AS (
SELECT id, cp0.parent FROM class_parent AS cp0 WHERE id = id_class_start
UNION ALL
SELECT cp.id, cp.parent
FROM class_parent AS cp
JOIN tree AS t ON cp.id = t.parent
)
SELECT * FROM tree;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_all_class_parents() RETURNS TABLE (
id integer,
parents integer[]
) AS $$
-- a version that will generate the transitive parents for all records
-- for this it is better to populate top down
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parents) AS (
SELECT parent, ARRAY[]::integer[] FROM -- start from nodes with no parents
(SELECT cp0.parent FROM class_parent AS cp0 EXCEPT SELECT cp1.id FROM class_parent AS cp1)
UNION ALL
SELECT cp.id, cp.parent || t.parents
FROM class_parent AS cp
JOIN tree AS t ON cp.parent = t.child
)
SELECT * FROM tree;

END;
$$ language plpgsql;

-------- instances

CREATE OR REPLACE FUNCTION get_instance_parents(id_instance_start integer) RETURNS TABLE (
parent integer
) AS $$
-- single transitive parent list
BEGIN
RETURN QUERY
WITH RECURSIVE tree(id) AS (
SELECT ip0.parent FROM instance_parent AS ip0 WHERE id = id_instance_start
UNION ALL
SELECT ip.parent
FROM instance_parent AS ip
JOIN tree AS t ON ip.id = t.id
)
SELECT * FROM tree;
END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_instance_parent_edges(id_instance_start integer) RETURNS TABLE (
child integer,
parent integer
) AS $$
-- a slightly easier to read version that returns the edges
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parent) AS (
SELECT id, ip0.parent FROM instance_parent AS ip0 WHERE id = id_instance_start
UNION ALL
SELECT ip.id, ip.parent
FROM instance_parent AS ip
JOIN tree AS t ON ip.id = t.parent
)
SELECT * FROM tree;

END;
$$ language plpgsql;

CREATE OR REPLACE FUNCTION get_all_instance_parents() RETURNS TABLE (
id integer,
parents integer[]
) AS $$
-- a version that will generate the transitive parents for all records
-- for this it is better to populate top down
BEGIN
RETURN QUERY
WITH RECURSIVE tree(child, parents) AS (
SELECT parent, ARRAY[]::integer[] FROM -- start from nodes with no parents
(SELECT ip0.parent FROM instance_parent AS ip0 EXCEPT SELECT ip1.id FROM instance_parent AS ip1)
UNION ALL
SELECT ip.id, ip.parent || t.parents
FROM instance_parent AS ip
JOIN tree AS t ON ip.parent = t.child
)
SELECT * FROM tree;

END;
$$ language plpgsql;


CREATE OR REPLACE FUNCTION check_inst_susa_parent() RETURNS trigger as $$
-- FIXME as implemented the user has to know when to call this function OR we have to make it
-- run as a trigger after any insert into and require that insert into values must include the
-- full parent hierarchy for any and all instances that have been added to the instance_parent
-- table ... actually ... this could run as a trigger if we require that inserts into the
-- instance_parent table always be done in order so that the parents are always in the table
-- before the children, it does mean that we can disable the trigger when loading from a dump
-- though ...
DECLARE
rec record;
BEGIN

WITH
parents AS (SELECT im FROM instance_measured AS im WHERE im.id IN (SELECT * FROM get_instance_parents(NEW.id))),
subjects AS (SELECT suim FROM instance_measured AS im
JOIN instance_measured AS suim ON im.dataset = suim.dataset AND suim.formal_id = im.sub_id
WHERE im.id = NEW.id),
samples AS (SELECT saim FROM instance_measured AS im
JOIN instance_measured AS saim ON im.dataset = saim.dataset AND saim.formal_id = im.sam_id
WHERE im.id = NEW.id)
SELECT -- FIXME surely there is a more efficient way to do this
(((SELECT count(*) FROM samples) > 0 OR  (SELECT count(*) from subjects) > 0) AND (SELECT count(*) FROM parents) = 0) AS one,
( (SELECT count(*) FROM samples) = 0 AND (SELECT count(*) from subjects) = 0  AND (SELECT count(*) FROM parents) > 0) AS two,
(    (SELECT count(*) FROM (SELECT * FROM parents INTERSECT SELECT * FROM subjects)) = (SELECT count(*) FROM subjects)
AND  (SELECT count(*) FROM (SELECT * FROM parents INTERSECT SELECT * FROM samples))  = (SELECT count(*) FROM samples)) AS three
/*
-- we cannot check against parents in this last case because it can contain intermediates therefore we can only check parents contain all referenced subjects and samples, going the other way around we know we will be missing any intervening samples, but those will have been checked when they were inserted
AND  (SELECT count(*) FROM (SELECT * FROM parents INTERSECT SELECT * FROM (SELECT * FROM subjects UNION SELECT * FROM samples))) = (SELECT count(*) FROM parents))
*/
INTO rec;

/*
FIXME TODO must handle the multi-parent case, which can happen when samples are
derived from multiple subjects, in those cases if we want this to work as it does
now then we have to reify subject populations and sample populations for the purposes
of referential integrity
*/

IF rec.one THEN

RAISE EXCEPTION 'parents missing for instance which references a subject or a sample: % % %', NEW.id, NEW.sub_id, NEW.sam_id
USING HINT = 'forgot to insert into the parents table';

ELSIF rec.two THEN

RAISE EXCEPTION 'subjects and samples missing on instance when there are parents: % %', NEW.id, (SELECT * FROM get_instance_parents(NEW.id))
USING HINT = 'instance did not include subject/sample reference when there should have been one';

ELSIF NOT rec.three THEN

RAISE EXCEPTION 'mismatch between parents, subjects, or samples: % % % %', NEW.id, (SELECT * FROM get_instance_parents(NEW.id)), NEW.sub_id, NEW.sam_id
USING HINT = 'there might be extra parents, subjects, or samples, check the set differences';

END IF;

RETURN NULL;

END;
$$ language plpgsql;

CREATE OR REPLACE TRIGGER trigger_af_ins_instance_parent AFTER INSERT ON instance_parent FOR EACH ROW EXECUTE PROCEDURE check_inst_susa_parent();
